{
  "$schema": "http://cyclonedx.org/schema/bom-1.6.schema.json",
  "bomFormat": "CycloneDX",
  "specVersion": "1.6",
  "serialNumber": "urn:uuid:e239dc71-b20e-4bda-8aae-3a0bab4a623b",
  "version": 1,
  "metadata": {
    "timestamp": "2025-07-14T13:27:43-04:00",
    "tools": {
      "components": [
        {
          "type": "application",
          "author": "anchore",
          "name": "syft",
          "version": "1.28.0"
        }
      ]
    },
    "component": {
      "bom-ref": "ac2777748a1ebb94",
      "type": "file",
      "name": "Symphonia-0.5.4/"
    }
  },
  "components": [
    {
      "bom-ref": "pkg:github/actions-rs/cargo@v1?package-id=e5220b1065449633",
      "type": "library",
      "name": "actions-rs/cargo",
      "version": "v1",
      "cpe": "cpe:2.3:a:actions-rs\\/cargo:actions-rs\\/cargo:v1:*:*:*:*:*:*:*",
      "purl": "pkg:github/actions-rs/cargo@v1",
      "properties": [
        {
          "name": "syft:package:foundBy",
          "value": "github-actions-usage-cataloger"
        },
        {
          "name": "syft:package:type",
          "value": "github-action"
        },
        {
          "name": "syft:package:metadataType",
          "value": "github-actions-use-statement"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions-rs\\/cargo:actions_rs\\/cargo:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions_rs\\/cargo:actions-rs\\/cargo:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions_rs\\/cargo:actions_rs\\/cargo:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions:actions-rs\\/cargo:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions:actions_rs\\/cargo:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:location:0:path",
          "value": "/.github/workflows/ci.yml"
        }
      ]
    },
    {
      "bom-ref": "pkg:github/actions-rs/toolchain@v1?package-id=e4495d536f0d4767",
      "type": "library",
      "name": "actions-rs/toolchain",
      "version": "v1",
      "cpe": "cpe:2.3:a:actions-rs\\/toolchain:actions-rs\\/toolchain:v1:*:*:*:*:*:*:*",
      "purl": "pkg:github/actions-rs/toolchain@v1",
      "properties": [
        {
          "name": "syft:package:foundBy",
          "value": "github-actions-usage-cataloger"
        },
        {
          "name": "syft:package:type",
          "value": "github-action"
        },
        {
          "name": "syft:package:metadataType",
          "value": "github-actions-use-statement"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions-rs\\/toolchain:actions_rs\\/toolchain:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions_rs\\/toolchain:actions-rs\\/toolchain:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions_rs\\/toolchain:actions_rs\\/toolchain:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions:actions-rs\\/toolchain:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:cpe23",
          "value": "cpe:2.3:a:actions:actions_rs\\/toolchain:v1:*:*:*:*:*:*:*"
        },
        {
          "name": "syft:location:0:path",
          "value": "/.github/workflows/ci.yml"
        }
      ]
    },
    {
      "bom-ref": "pkg:github/actions/checkout@v1?package-id=77817cdec8a27024",
      "type": "library",
      "name": "actions/checkout",
      "version": "v1",
      "cpe": "cpe:2.3:a:actions\\/checkout:actions\\/checkout:v1:*:*:*:*:*:*:*",
      "purl": "pkg:github/actions/checkout@v1",
      "properties": [
        {
          "name": "syft:package:foundBy",
          "value": "github-actions-usage-cataloger"
        },
        {
          "name": "syft:package:type",
          "value": "github-action"
        },
        {
          "name": "syft:package:metadataType",
          "value": "github-actions-use-statement"
        },
        {
          "name": "syft:location:0:path",
          "value": "/.github/workflows/ci.yml"
        }
      ]
    },
    {
      "bom-ref": "7561d461b00ff11d",
      "type": "file",
      "name": "/home/Symphonia-0.5.4/.github/workflows/ci.yml",
      "hashes": [
        {
          "alg": "SHA-1",
          "content": "3dc680335aae2494b6134528054379cf4b15646a"
        },
        {
          "alg": "SHA-256",
          "content": "ab991319cb34a6f7430b10f51410f68effa21182bba24e04a2d0fa48395a2f11"
        }
      ]
    }
  ],
  "upgrade": {
    "file_changes": {
      "old_version": "/home/Symphonia-0.5.2",
      "New file": [
        "/home/Symphonia-0.5.4/symphonia-core/src/dsp/mdct/mod.rs",
        "/home/Symphonia-0.5.4/symphonia-core/src/dsp/mdct/no_simd.rs",
        "/home/Symphonia-0.5.4/symphonia-core/src/dsp/mdct/simd.rs",
        "/home/Symphonia-0.5.4/symphonia-format-caf/src/chunks.rs",
        "/home/Symphonia-0.5.4/symphonia-format-caf/src/demuxer.rs",
        "/home/Symphonia-0.5.4/symphonia-format-caf/src/lib.rs",
        "/home/Symphonia-0.5.4/symphonia-format-riff/src/aiff/chunks.rs",
        "/home/Symphonia-0.5.4/symphonia-format-riff/src/aiff/mod.rs",
        "/home/Symphonia-0.5.4/symphonia-format-riff/src/common.rs",
        "/home/Symphonia-0.5.4/symphonia-format-riff/src/lib.rs",
        "/home/Symphonia-0.5.4/symphonia-format-riff/src/wave/chunks.rs",
        "/home/Symphonia-0.5.4/symphonia-format-riff/src/wave/mod.rs",
        "/home/Symphonia-0.5.4/symphonia-metadata/src/flac.rs"
      ],
      "Deleted file": [
        "/home/Symphonia-0.5.2/symphonia-core/src/dsp/mdct.rs"
      ],
      "Modified file": [
        {
          "file": "/home/Symphonia-0.5.4/symphonia/examples/getting-started.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia/examples/getting-started.rs",
            "+++ /home/Symphonia-0.5.4/symphonia/examples/getting-started.rs",
            "@@ -59,15 +59,15 @@",
            "                 // The track list has been changed. Re-examine it and create a new set of decoders,",
            "                 // then restart the decode loop. This is an advanced feature and it is not",
            "                 // unreasonable to consider this \"the end.\" As of v0.5.0, the only usage of this is",
            "                 // for chained OGG physical streams.",
            "                 unimplemented!();",
            "             }",
            "             Err(err) => {",
            "-                // A unrecoverable error occured, halt decoding.",
            "+                // A unrecoverable error occurred, halt decoding.",
            "                 panic!(\"{}\", err);",
            "             }",
            "         };",
            " ",
            "         // Consume any new metadata that has been read since the last packet.",
            "         while !format.metadata().is_latest() {",
            "             // Pop the old head of the metadata queue.",
            "@@ -91,13 +91,13 @@",
            "                 continue;",
            "             }",
            "             Err(Error::DecodeError(_)) => {",
            "                 // The packet failed to decode due to invalid data, skip the packet.",
            "                 continue;",
            "             }",
            "             Err(err) => {",
            "-                // An unrecoverable error occured, halt decoding.",
            "+                // An unrecoverable error occurred, halt decoding.",
            "                 panic!(\"{}\", err);",
            "             }",
            "         }",
            "     }",
            " }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia/src/lib.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia/src/lib.rs",
            "+++ /home/Symphonia-0.5.4/symphonia/src/lib.rs",
            "@@ -22,14 +22,16 @@",
            " //!",
            " //! ## Formats",
            " //!",
            " //! The following container formats are supported.",
            " //!",
            " //! | Format   | Feature Flag | Gapless* | Default |",
            " //! |----------|--------------|----------|---------|",
            "+//! | AIFF     | `aiff`       | Yes      | No      |",
            "+//! | CAF      | `caf`        | No       | No      |",
            " //! | ISO/MP4  | `isomp4`     | No       | No      |",
            " //! | MKV/WebM | `mkv`        | No       | Yes     |",
            " //! | OGG      | `ogg`        | Yes      | Yes     |",
            " //! | Wave     | `wav`        | Yes      | Yes     |",
            " //!",
            " //! \\* Gapless playback requires support from both the demuxer and decoder.",
            " //!",
            "@@ -60,14 +62,28 @@",
            " //!",
            " //! * ID3v1",
            " //! * ID3v2",
            " //! * ISO/MP4",
            " //! * RIFF",
            " //! * Vorbis Comment (in OGG & FLAC)",
            " //!",
            "+//! ## Optimizations",
            "+//!",
            "+//! SIMD optimizations are **not** enabled by default. They may be enabled on a per-instruction",
            "+//! set basis using the following feature flags. Enabling any SIMD support feature flags will pull",
            "+//! in the `rustfft` dependency.",
            "+//!",
            "+//! | Instruction Set | Feature Flag    | Default |",
            "+//! |-----------------|-----------------|---------|",
            "+//! | SSE             | `opt-simd-sse`  | No      |",
            "+//! | AVX             | `opt-simd-avx`  | No      |",
            "+//! | Neon            | `opt-simd-neon` | No      |",
            "+//!",
            "+//! **Tip:** All SIMD optimizations can be enabled with the `opt-simd` feature flag.",
            "+//!",
            " //! # Usage",
            " //!",
            " //! The following steps describe a basic usage of Symphonia:",
            " //!",
            " //! 1.  Instantiate a [`CodecRegistry`][core::codecs::CodecRegistry] and register all the codecs",
            " //!     that are of interest. Alternatively, you may use [`default::get_codecs`] to get the default",
            " //!     registry with all the enabled codecs pre-registered. The registry will be used to",
            "@@ -151,22 +167,26 @@",
            " ",
            "         #[cfg(feature = \"flac\")]",
            "         pub use symphonia_bundle_flac::FlacReader;",
            "         #[cfg(any(feature = \"mp1\", feature = \"mp2\", feature = \"mp3\"))]",
            "         pub use symphonia_bundle_mp3::MpaReader;",
            "         #[cfg(feature = \"aac\")]",
            "         pub use symphonia_codec_aac::AdtsReader;",
            "+        #[cfg(feature = \"caf\")]",
            "+        pub use symphonia_format_caf::CafReader;",
            "         #[cfg(feature = \"isomp4\")]",
            "         pub use symphonia_format_isomp4::IsoMp4Reader;",
            "         #[cfg(feature = \"mkv\")]",
            "         pub use symphonia_format_mkv::MkvReader;",
            "         #[cfg(feature = \"ogg\")]",
            "         pub use symphonia_format_ogg::OggReader;",
            "+        #[cfg(feature = \"aiff\")]",
            "+        pub use symphonia_format_riff::AiffReader;",
            "         #[cfg(feature = \"wav\")]",
            "-        pub use symphonia_format_wav::WavReader;",
            "+        pub use symphonia_format_riff::WavReader;",
            " ",
            "         #[deprecated = \"use `default::formats::MpaReader` instead\"]",
            "         #[cfg(any(feature = \"mp1\", feature = \"mp2\", feature = \"mp3\"))]",
            "         pub type Mp3Reader = MpaReader;",
            "     }",
            " ",
            "     use lazy_static::lazy_static;",
            "@@ -246,23 +266,29 @@",
            "     pub fn register_enabled_formats(probe: &mut Probe) {",
            "         use symphonia_metadata::id3v2::Id3v2Reader;",
            " ",
            "         // Formats",
            "         #[cfg(feature = \"aac\")]",
            "         probe.register_all::<formats::AdtsReader>();",
            " ",
            "+        #[cfg(feature = \"caf\")]",
            "+        probe.register_all::<formats::CafReader>();",
            "+",
            "         #[cfg(feature = \"flac\")]",
            "         probe.register_all::<formats::FlacReader>();",
            " ",
            "         #[cfg(feature = \"isomp4\")]",
            "         probe.register_all::<formats::IsoMp4Reader>();",
            " ",
            "         #[cfg(any(feature = \"mp1\", feature = \"mp2\", feature = \"mp3\"))]",
            "         probe.register_all::<formats::MpaReader>();",
            " ",
            "+        #[cfg(feature = \"aiff\")]",
            "+        probe.register_all::<formats::AiffReader>();",
            "+",
            "         #[cfg(feature = \"wav\")]",
            "         probe.register_all::<formats::WavReader>();",
            " ",
            "         #[cfg(feature = \"ogg\")]",
            "         probe.register_all::<formats::OggReader>();",
            " ",
            "         #[cfg(feature = \"mkv\")]"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-flac/src/decoder.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-flac/src/decoder.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-flac/src/decoder.rs",
            "@@ -2,14 +2,15 @@",
            " // Copyright (c) 2019-2022 The Project Symphonia Developers.",
            " //",
            " // This Source Code Form is subject to the terms of the Mozilla Public",
            " // License, v. 2.0. If a copy of the MPL was not distributed with this",
            " // file, You can obtain one at https://mozilla.org/MPL/2.0/.",
            " ",
            " use std::cmp;",
            "+use std::convert::TryInto;",
            " use std::num::Wrapping;",
            " ",
            " use symphonia_core::audio::{AsAudioBufferRef, AudioBuffer, AudioBufferRef};",
            " use symphonia_core::audio::{Signal, SignalSpec};",
            " use symphonia_core::codecs::{",
            "     CodecDescriptor, CodecParameters, VerificationCheck, CODEC_TYPE_FLAC,",
            " };",
            "@@ -395,85 +396,65 @@",
            "     decode_residual(bs, order, buf)?;",
            " ",
            "     // Run the Fixed predictor (appends to residuals).",
            "     //",
            "     // TODO: The fixed predictor uses 64-bit accumulators by default to support bps > 26. On 64-bit",
            "     // machines, this is preferable, but on 32-bit machines if bps <= 26, run a 32-bit predictor,",
            "     // and fallback to the 64-bit predictor if necessary (which is basically never).",
            "-    fixed_predict(order, buf)?;",
            "+    fixed_predict(order, buf);",
            " ",
            "     Ok(())",
            " }",
            " ",
            " fn decode_linear<B: ReadBitsLtr>(bs: &mut B, bps: u32, order: u32, buf: &mut [i32]) -> Result<()> {",
            "     // The order of the Linear Predictor should be between 1 and 32.",
            "     debug_assert!(order > 0 && order <= 32);",
            " ",
            "     // The first `order` samples are encoded verbatim to warm-up the LPC decoder.",
            "     decode_verbatim(bs, bps, &mut buf[0..order as usize])?;",
            " ",
            "-    // Quantized linear predictor (QLP) coefficients precision in bits.",
            "+    // Quantized linear predictor (QLP) coefficients precision in bits (1-16).",
            "     let qlp_precision = bs.read_bits_leq32(4)? + 1;",
            "+",
            "     if qlp_precision > 15 {",
            "         return decode_error(\"flac: qlp precision set to reserved value\");",
            "     }",
            " ",
            "     // QLP coefficients bit shift [-16, 15].",
            "     let qlp_coeff_shift = sign_extend_leq32_to_i32(bs.read_bits_leq32(5)?, 5);",
            " ",
            "     if qlp_coeff_shift >= 0 {",
            "-        // Pick the best sized linear predictor to use based on the order. Most if not all FLAC",
            "-        // streams apppear to have an order <= 12. Specializing a predictor for orders <= 6 and",
            "-        // <= 12 appears to give the best performance.",
            "-        //",
            "-        // TODO: Reduce code duplication here.",
            "-        if order <= 4 {",
            "-            let mut qlp_coeffs = [0i32; 4];",
            "-",
            "-            for c in qlp_coeffs[4 - order as usize..4].iter_mut().rev() {",
            "-                *c = sign_extend_leq32_to_i32(bs.read_bits_leq32(qlp_precision)?, qlp_precision);",
            "-            }",
            "-",
            "-            decode_residual(bs, order, buf)?;",
            "+        let mut qlp_coeffs = [0i32; 32];",
            " ",
            "-            lpc_predict_4(order as usize, &qlp_coeffs, qlp_coeff_shift as u32, buf)?;",
            "+        for c in qlp_coeffs.iter_mut().rev().take(order as usize) {",
            "+            *c = sign_extend_leq32_to_i32(bs.read_bits_leq32(qlp_precision)?, qlp_precision);",
            "         }",
            "-        else if order <= 8 {",
            "-            let mut qlp_coeffs = [0i32; 8];",
            "-",
            "-            for c in qlp_coeffs[8 - order as usize..8].iter_mut().rev() {",
            "-                *c = sign_extend_leq32_to_i32(bs.read_bits_leq32(qlp_precision)?, qlp_precision);",
            "-            }",
            "-",
            "-            decode_residual(bs, order, buf)?;",
            "-",
            "-            lpc_predict_8(order as usize, &qlp_coeffs, qlp_coeff_shift as u32, buf)?;",
            "-        }",
            "-        else if order <= 12 {",
            "-            let mut qlp_coeffs = [0i32; 12];",
            "-",
            "-            for c in qlp_coeffs[12 - order as usize..12].iter_mut().rev() {",
            "-                *c = sign_extend_leq32_to_i32(bs.read_bits_leq32(qlp_precision)?, qlp_precision);",
            "-            }",
            "-",
            "-            decode_residual(bs, order, buf)?;",
            "-",
            "-            lpc_predict_12(order as usize, &qlp_coeffs, qlp_coeff_shift as u32, buf)?;",
            "-        }",
            "-        else {",
            "-            let mut qlp_coeffs = [0i32; 32];",
            "-",
            "-            for c in qlp_coeffs[32 - order as usize..32].iter_mut().rev() {",
            "-                *c = sign_extend_leq32_to_i32(bs.read_bits_leq32(qlp_precision)?, qlp_precision);",
            "-            }",
            " ",
            "-            decode_residual(bs, order, buf)?;",
            "+        decode_residual(bs, order, buf)?;",
            " ",
            "-            lpc_predict_32(order as usize, &qlp_coeffs, qlp_coeff_shift as u32, buf)?;",
            "-        }",
            "+        // Helper function to dispatch to a predictor with a maximum order of N.",
            "+        #[inline(always)]",
            "+        fn lpc<const N: usize>(order: u32, coeffs: &[i32; 32], coeff_shift: i32, buf: &mut [i32]) {",
            "+            let coeffs_n = (&coeffs[32 - N..32]).try_into().unwrap();",
            "+            lpc_predict::<N>(order as usize, coeffs_n, coeff_shift as u32, buf);",
            "+        }",
            "+",
            "+        // Pick the best length linear predictor to use based on the order. Most FLAC streams use",
            "+        // the subset format and have an order <= 12. Therefore, for orders <= 12, dispatch to",
            "+        // predictors that roughly match the order. If a predictor is too long for a given order,",
            "+        // then there will be wasted computations. On the other hand, it is not worth the code bloat",
            "+        // to specialize for every order <= 12.",
            "+        match order {",
            "+            0..=4 => lpc::<4>(order, &qlp_coeffs, qlp_coeff_shift, buf),",
            "+            5..=6 => lpc::<6>(order, &qlp_coeffs, qlp_coeff_shift, buf),",
            "+            7..=8 => lpc::<8>(order, &qlp_coeffs, qlp_coeff_shift, buf),",
            "+            9..=10 => lpc::<10>(order, &qlp_coeffs, qlp_coeff_shift, buf),",
            "+            11..=12 => lpc::<12>(order, &qlp_coeffs, qlp_coeff_shift, buf),",
            "+            _ => lpc::<32>(order, &qlp_coeffs, qlp_coeff_shift, buf),",
            "+        };",
            "     }",
            "     else {",
            "         return unsupported_error(\"flac: lpc shifts less than 0 are not supported\");",
            "     }",
            " ",
            "     Ok(())",
            " }",
            "@@ -496,15 +477,15 @@",
            "             return decode_error(\"flac: residual method set to reserved value\");",
            "         }",
            "     };",
            " ",
            "     // Read the partition order.",
            "     let order = bs.read_bits_leq32(4)?;",
            " ",
            "-    // The number of paritions is equal to 2^order.",
            "+    // The number of partitions is equal to 2^order.",
            "     let n_partitions = 1usize << order;",
            " ",
            "     // In general, all partitions have the same number of samples such that the sum of all partition",
            "     // lengths equal the block length. The number of samples in a partition can therefore be",
            "     // calculated with block_size / 2^order *in general*. However, since there are warm-up samples",
            "     // stored verbatim, the first partition has n_prelude_samples less samples. Likewise, if there",
            "     // is only one partition, then it too has n_prelude_samples less samples.",
            "@@ -624,15 +605,15 @@",
            "     assert_eq!(rice_signed_to_i32(8), 4);",
            "     assert_eq!(rice_signed_to_i32(9), -5);",
            "     assert_eq!(rice_signed_to_i32(10), 5);",
            " ",
            "     assert_eq!(rice_signed_to_i32(u32::max_value()), -2_147_483_648);",
            " }",
            " ",
            "-fn fixed_predict(order: u32, buf: &mut [i32]) -> Result<()> {",
            "+fn fixed_predict(order: u32, buf: &mut [i32]) {",
            "     debug_assert!(order <= 4);",
            " ",
            "     // The Fixed Predictor is just a hard-coded version of the Linear Predictor up to order 4 and",
            "     // with fixed coefficients. Some cases may be simplified such as orders 0 and 1. For orders 2",
            "     // through 4, use the same IIR-style algorithm as the Linear Predictor.",
            "     match order {",
            "         // A 0th order predictor always predicts 0, and therefore adds nothing to any of the samples",
            "@@ -671,80 +652,50 @@",
            "                 let c = Wrapping(-6) * Wrapping(i64::from(buf[i - 2]));",
            "                 let d = Wrapping(4) * Wrapping(i64::from(buf[i - 1]));",
            "                 buf[i] += (a + b + c + d).0 as i32;",
            "             }",
            "         }",
            "         _ => unreachable!(),",
            "     };",
            "-",
            "-    Ok(())",
            " }",
            " ",
            "-/// Generalized Linear Predictive Coding (LPC) decoder macro for orders >= 4. The exact number of",
            "-/// coefficients given is specified by `order`. Coefficients must be stored in reverse order in",
            "-/// `coeffs` with the first coefficient at index 31. Coefficients at indicies less than",
            "-/// 31 - `order` must be 0. It is expected that the first `order` samples in `buf` are warm-up",
            "-/// samples.",
            "-macro_rules! lpc_predictor {",
            "-    ($func_name:ident, $order:expr) => {",
            "-        fn $func_name(",
            "-            order: usize,",
            "-            coeffs: &[i32; $order],",
            "-            coeff_shift: u32,",
            "-            buf: &mut [i32],",
            "-        ) -> Result<()> {",
            "-            // Order must be less than or equal to the number of coefficients.",
            "-            debug_assert!(order as usize <= coeffs.len());",
            "-",
            "-            // Order must be less than to equal to the number of samples the buffer can hold.",
            "-            debug_assert!(order as usize <= buf.len());",
            "-",
            "-            let n_prefill = cmp::min($order, buf.len()) - order;",
            "-",
            "-            // If the pre-fill computation filled the entire sample buffer, return immediately since",
            "-            // the main predictor requires atleast 32 samples to be present in the buffer.",
            "-            for i in order..order + n_prefill {",
            "-                let predicted = coeffs[$order - order..$order]",
            "-                    .iter()",
            "-                    .zip(&buf[i - order..i])",
            "-                    .map(|(&c, &sample)| c as i64 * sample as i64)",
            "-                    .sum::<i64>();",
            "-",
            "-                buf[i] += (predicted >> coeff_shift) as i32;",
            "-            }",
            "-",
            "-            if buf.len() <= $order {",
            "-                return Ok(());",
            "-            }",
            "+/// Generalized Linear Predictive Coding (LPC) decoder. The exact number of coefficients given is",
            "+/// specified by `order`. Coefficients must be stored in reverse order in `coeffs` with the first",
            "+/// coefficient at index 31. Coefficients at indices less than 31 - `order` must be 0.",
            "+/// It is expected that the first `order` samples in `buf` are warm-up samples.",
            "+fn lpc_predict<const N: usize>(order: usize, coeffs: &[i32; N], coeff_shift: u32, buf: &mut [i32]) {",
            "+    // Order must be less than or equal to the number of coefficients.",
            "+    debug_assert!(order <= coeffs.len());",
            "+",
            "+    // Order must be less than to equal to the number of samples the buffer can hold.",
            "+    debug_assert!(order <= buf.len());",
            "+",
            "+    // The main, efficient, predictor loop needs N previous samples to run. Since order <= N,",
            "+    // calculate enough samples to reach N.",
            "+    let n_prefill = cmp::min(N, buf.len()) - order;",
            "+",
            "+    for i in order..order + n_prefill {",
            "+        let predicted = coeffs[N - order..N]",
            "+            .iter()",
            "+            .zip(&buf[i - order..i])",
            "+            .map(|(&c, &sample)| c as i64 * sample as i64)",
            "+            .sum::<i64>();",
            "+",
            "+        buf[i] += (predicted >> coeff_shift) as i32;",
            "+    }",
            "+",
            "+    // If the pre-fill operation filled the entire sample buffer, return immediately.",
            "+    if buf.len() <= N {",
            "+        return;",
            "+    }",
            "+",
            "+    // Main predictor loop. Calculate each sample by applying what is essentially an IIR filter.",
            "+    for i in N..buf.len() {",
            "+        let predicted = coeffs",
            "+            .iter()",
            "+            .zip(&buf[i - N..i])",
            "+            .map(|(&c, &s)| i64::from(c) * i64::from(s))",
            "+            .sum::<i64>();",
            " ",
            "-            for i in $order..buf.len() {",
            "-                // Predict each sample by applying what is essentially an IIR filter.",
            "-                //",
            "-                // This implementation supersedes an iterator based approach where coeffs and",
            "-                // samples were zipped together, multiplied together via map, and then summed. That",
            "-                // implementation did not pipeline well since summing was performed before the next",
            "-                // multiplication, introducing pipleine stalls. This unrolled approach is much",
            "-                // faster atleast on Intel hardware.",
            "-                let s = &buf[i - $order..i];",
            "-",
            "-                let mut predicted = 0i64;",
            "-",
            "-                for j in 0..($order / 4) {",
            "-                    let a = coeffs[4 * j + 0] as i64 * s[4 * j + 0] as i64;",
            "-                    let b = coeffs[4 * j + 1] as i64 * s[4 * j + 1] as i64;",
            "-                    let c = coeffs[4 * j + 2] as i64 * s[4 * j + 2] as i64;",
            "-                    let d = coeffs[4 * j + 3] as i64 * s[4 * j + 3] as i64;",
            "-                    predicted += a + b + c + d;",
            "-                }",
            "-",
            "-                buf[i] += (predicted >> coeff_shift) as i32;",
            "-            }",
            "-",
            "-            Ok(())",
            "-        }",
            "-    };",
            "+        buf[i] += (predicted >> coeff_shift) as i32;",
            "+    }",
            " }",
            "-",
            "-lpc_predictor!(lpc_predict_32, 32);",
            "-lpc_predictor!(lpc_predict_12, 12);",
            "-lpc_predictor!(lpc_predict_8, 8);",
            "-lpc_predictor!(lpc_predict_4, 4);"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-flac/src/demuxer.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-flac/src/demuxer.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-flac/src/demuxer.rs",
            "@@ -262,15 +262,15 @@",
            "                 self.reader.seek(SeekFrom::Start(mid_byte_offset))?;",
            " ",
            "                 let sync = self.parser.resync(&mut self.reader)?;",
            " ",
            "                 if ts < sync.ts {",
            "                     end_byte_offset = mid_byte_offset;",
            "                 }",
            "-                else if ts > sync.ts && ts < sync.ts + sync.dur {",
            "+                else if ts >= sync.ts && ts < sync.ts + sync.dur {",
            "                     debug!(\"seeked to ts={} (delta={})\", sync.ts, sync.ts as i64 - ts as i64);",
            " ",
            "                     return Ok(SeekedTo { track_id: 0, actual_ts: sync.ts, required_ts: ts });",
            "                 }",
            "                 else {",
            "                     start_byte_offset = mid_byte_offset;",
            "                 }",
            "@@ -284,15 +284,15 @@",
            "         // Linearly search the stream packet-by-packet for the packet that contains the desired",
            "         // timestamp. This search is used to find the exact packet containing the desired timestamp",
            "         // after the search range was narrowed by the binary search. It is also the ONLY way for a",
            "         // unseekable stream to be \"seeked\" forward.",
            "         let packet = loop {",
            "             let sync = self.parser.resync(&mut self.reader)?;",
            " ",
            "-            // The desired timestamp preceeds the current packet's timestamp.",
            "+            // The desired timestamp precedes the current packet's timestamp.",
            "             if ts < sync.ts {",
            "                 // Attempted to seek backwards on an unseekable stream.",
            "                 if !self.reader.is_seekable() {",
            "                     return seek_error(SeekErrorKind::ForwardOnly);",
            "                 }",
            "                 // Overshot a regular seek, or the stream is corrupted, not necessarily an error",
            "                 // per-say."
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-flac/src/parser.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-flac/src/parser.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-flac/src/parser.rs",
            "@@ -455,33 +455,37 @@",
            "     /// Resync the reader to the start of the next frame.",
            "     pub fn resync<B>(&mut self, reader: &mut B) -> Result<SyncInfo>",
            "     where",
            "         B: ReadBytes + SeekBuffered,",
            "     {",
            "         let init_pos = reader.pos();",
            " ",
            "-        let mut byte_offset;",
            "+        let mut frame_pos;",
            " ",
            "         let header = loop {",
            "             let sync = sync_frame(reader)?;",
            " ",
            "-            byte_offset = reader.pos() - 2;",
            "+            frame_pos = reader.pos() - 2;",
            " ",
            "             if let Ok(header) = read_frame_header(reader, sync) {",
            "                 // Do a strict frame header check with no previous header.",
            "                 if strict_frame_header_check(&self.info, &header, None) {",
            "                     break header;",
            "                 }",
            "             }",
            "+",
            "+            // If the header check failed, then seek to one byte past the start of the false frame",
            "+            // and continue trying to resynchronize.",
            "+            reader.seek_buffered(frame_pos + 1);",
            "         };",
            " ",
            "         let sync = calc_sync_info(&self.info, &header);",
            " ",
            "         // Rewind reader back to the start of the frame.",
            "-        reader.seek_buffered_rev((reader.pos() - byte_offset) as usize);",
            "+        reader.seek_buffered(frame_pos);",
            " ",
            "         // If the reader was moved, soft reset the parser.",
            "         if init_pos != reader.pos() {",
            "             self.soft_reset();",
            "         }",
            " ",
            "         Ok(sync)"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-mp3/src/header.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-mp3/src/header.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-mp3/src/header.rs",
            "@@ -61,18 +61,14 @@",
            "     if (header >> 12) & 0xf == 0xf {",
            "         return false;",
            "     }",
            "     // Sample rate (0x3 is not allowed).",
            "     if (header >> 10) & 0x3 == 0x3 {",
            "         return false;",
            "     }",
            "-    // Emphasis (0x2 is not allowed)",
            "-    if header & 0x3 == 0x2 {",
            "-        return false;",
            "-    }",
            "     true",
            " }",
            " ",
            " /// Returns true if the provided frame header word is synced.",
            " #[inline(always)]",
            " pub fn is_frame_header_word_synced(sync: u32) -> bool {",
            "     (sync & 0xffe0_0000) == 0xffe0_0000",
            "@@ -186,18 +182,17 @@",
            "         }",
            "         else if bitrate == 32_000 || bitrate == 48_000 || bitrate == 56_000 || bitrate == 80_000 {",
            "             return decode_error(\"mpa: invalid Layer 2 bitrate for non-mono channel mode\");",
            "         }",
            "     }",
            " ",
            "     let emphasis = match header & 0x3 {",
            "-        0b00 => Emphasis::None,",
            "         0b01 => Emphasis::Fifty15,",
            "         0b11 => Emphasis::CcitJ17,",
            "-        _ => return decode_error(\"mpa: invalid emphasis\"),",
            "+        _ => Emphasis::None,",
            "     };",
            " ",
            "     let is_copyrighted = header & 0x8 != 0x0;",
            "     let is_original = header & 0x4 != 0x0;",
            "     let has_padding = header & 0x200 != 0;",
            " ",
            "     let has_crc = header & 0x1_0000 == 0;"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/codebooks.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-mp3/src/layer3/codebooks.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/codebooks.rs",
            "@@ -565,20 +565,23 @@",
            " ",
            "         for (codebook, table) in codebooks.iter_mut().zip(&MPEG_TABLES) {",
            "             assert!(table.codes.len() == table.lens.len());",
            " ",
            "             let len = table.codes.len() as u16;",
            " ",
            "             // Generate values for the codebook.",
            "-            let values: Vec<u16> = (0..len).into_iter()",
            "-                                           .map(|i| mpeg_gen_value(i, table.wrap))",
            "+            let values: Vec<u16> = (0..len).map(|i| mpeg_gen_value(i, table.wrap))",
            "                                            .collect();",
            " ",
            "             // Generate the codebook.",
            "             let mut builder = CodebookBuilder::new(BitOrder::Verbatim);",
            "+",
            "+            // Decode a maximum of 8 bits per read.",
            "+            builder.bits_per_read(8);",
            "+",
            "             *codebook = builder.make(table.codes, table.lens, &values).unwrap();",
            "         }",
            " ",
            "         codebooks",
            "     };",
            " }",
            " ",
            "@@ -588,19 +591,22 @@",
            " ",
            "         for (codebook, table) in codebooks.iter_mut().zip(&MPEG_QUADS_TABLES) {",
            "             assert!(table.codes.len() == table.lens.len());",
            " ",
            "             let len = table.codes.len() as u16;",
            " ",
            "             // Generate values for the codebook.",
            "-            let values: Vec<u16> = (0..len).into_iter()",
            "-                                           .map(|i| mpeg_gen_value(i, table.wrap))",
            "+            let values: Vec<u16> = (0..len).map(|i| mpeg_gen_value(i, table.wrap))",
            "                                            .collect();",
            " ",
            "             // Generate the codebook.",
            "             let mut builder = CodebookBuilder::new(BitOrder::Verbatim);",
            "+",
            "+            // Decode a maximum of 8 bits per read.",
            "+            builder.bits_per_read(8);",
            "+",
            "             *codebook = builder.make(table.codes, table.lens, &values).unwrap();",
            "         }",
            " ",
            "         codebooks",
            "     };",
            " }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/hybrid_synthesis.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-mp3/src/layer3/hybrid_synthesis.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/hybrid_synthesis.rs",
            "@@ -146,15 +146,15 @@",
            "         }",
            " ",
            "         (cs, ca)",
            "     };",
            " }",
            " ",
            " /// Reorder samples that are part of short blocks into sub-band order.",
            "-pub(super) fn reorder(header: &FrameHeader, channel: &GranuleChannel, buf: &mut [f32; 576]) {",
            "+pub(super) fn reorder(header: &FrameHeader, channel: &mut GranuleChannel, buf: &mut [f32; 576]) {",
            "     // Only short blocks are reordered.",
            "     if let BlockType::Short { is_mixed } = channel.block_type {",
            "         // Every short block is split into 3 equally sized windows as illustrated below (e.g. for",
            "         // a short scale factor band with win_len=4):",
            "         //",
            "         //    <- Window #1 ->  <- Window #2 ->  <- Window #3 ->",
            "         //   [ 0 | 1 | 2 | 3 ][ 4 | 5 | 6 | 7 ][ 8 | 9 | a | b ]",
            "@@ -174,66 +174,75 @@",
            "             let switch = SFB_MIXED_SWITCH_POINT[header.sample_rate_idx];",
            "             &SFB_MIXED_BANDS[header.sample_rate_idx][switch..]",
            "         }",
            "         else {",
            "             &SFB_SHORT_BANDS[header.sample_rate_idx]",
            "         };",
            " ",
            "-        let start = bands[0];",
            "-",
            "-        // TODO: Frankly, this is wasteful... Consider swapping between two internal buffers so we",
            "-        // can avoid initializing this to 0 every frame. Unsafe is not allowed in codec's so this",
            "-        // can't be left uninitialized.",
            "         let mut reorder_buf = [0f32; 576];",
            " ",
            "+        let start = bands[0];",
            "         let mut i = start;",
            " ",
            "         for (((s0, s1), s2), s3) in",
            "             bands.iter().zip(&bands[1..]).zip(&bands[2..]).zip(&bands[3..]).step_by(3)",
            "         {",
            "+            // Do not reorder short blocks that begin after the rzero partition boundary since",
            "+            // they're zeroed.",
            "+            if *s0 >= channel.rzero {",
            "+                break;",
            "+            }",
            "+",
            "             // The three short sample windows.",
            "             let win0 = &buf[*s0..*s1];",
            "             let win1 = &buf[*s1..*s2];",
            "             let win2 = &buf[*s2..*s3];",
            " ",
            "             // Interleave the three short sample windows.",
            "-            // TODO: This could likely be sped up with SIMD.",
            "             for ((w0, w1), w2) in win0.iter().zip(win1).zip(win2) {",
            "                 reorder_buf[i + 0] = *w0;",
            "                 reorder_buf[i + 1] = *w1;",
            "                 reorder_buf[i + 2] = *w2;",
            "                 i += 3;",
            "             }",
            "         }",
            " ",
            "-        // TODO: It is possible for i to exceed rzero, does that make sense? Or should it simply",
            "-        // copy between [start..rzero]? Probably not... since an entire scale factor band /should/",
            "-        // be processed...",
            "-",
            "         // Copy reordered samples from the reorder buffer to the actual sample buffer.",
            "         buf[start..i].copy_from_slice(&reorder_buf[start..i]);",
            "+",
            "+        // After reordering, the start of the rzero partition may no longer be valid. Update it.",
            "+        channel.rzero = channel.rzero.max(i);",
            "     }",
            " }",
            " ",
            " /// Applies the anti-aliasing filter to sub-bands that are not part of short blocks.",
            "-pub(super) fn antialias(channel: &GranuleChannel, samples: &mut [f32; 576]) {",
            "-    // The number of sub-bands to anti-aliasing depends on block type.",
            "-    let sb_end = match channel.block_type {",
            "+pub(super) fn antialias(channel: &mut GranuleChannel, samples: &mut [f32; 576]) {",
            "+    // The maximum number of sub-bands to anti-alias depends on block type.",
            "+    let sb_limit = match channel.block_type {",
            "         // Short blocks are never anti-aliased.",
            "         BlockType::Short { is_mixed: false } => return,",
            "         // Mixed blocks have a long block span the first 36 samples (2 sub-bands). Therefore, only",
            "         // anti-alias these two sub-bands.",
            "-        BlockType::Short { is_mixed: true } => 2 * 18,",
            "+        BlockType::Short { is_mixed: true } => 2,",
            "         // All other block types require all 32 sub-bands to be anti-aliased.",
            "-        _ => 32 * 18,",
            "+        _ => 32,",
            "     };",
            " ",
            "     // Amortize the lazy_static fetch over the entire anti-aliasing operation.",
            "     let (cs, ca): &([f32; 8], [f32; 8]) = &ANTIALIAS_CS_CA;",
            " ",
            "+    // The sub-band that intersects the start of the rzero partition. All sub-bands after this one",
            "+    // are zeroed and do-not need anti-aliasing.",
            "+    let sb_rzero = channel.rzero / 18;",
            "+",
            "+    // The anti-aliasing filter must be applied up-to the last non-zero sub-band. After",
            "+    // anti-aliasing, the first zeroed sub-band may have non-zero values \"smeared\" into it.",
            "+    // Therefore, the rzero must be updated.",
            "+    channel.rzero = 18 * sb_limit.min(sb_rzero + 2).min(32);",
            "+",
            "     // Anti-aliasing is performed using 8 butterfly calculations at the boundaries of ADJACENT",
            "     // sub-bands. For each calculation, there are two samples: lower and upper. For each iteration,",
            "     // the lower sample index advances backwards from the boundary, while the upper sample index",
            "     // advances forward from the boundary.",
            "     //",
            "     // For example, let B(li, ui) represent the butterfly calculation where li and ui are the",
            "     // indicies of the lower and upper samples respectively. If j is the index of the first sample",
            "@@ -251,15 +260,15 @@",
            "     //               /  \\  * ca[i]           where:",
            "     //             /     \\                       cs[i], ca[i] are constant values for iteration i,",
            "     //   u0 ------o------(+)-------> u1          derived from table B.9 of ISO/IEC 11172-3.",
            "     //             * cs[i]",
            "     //",
            "     // Note that all butterfly calculations only involve two samples, and all iterations are",
            "     // independant of each other. This lends itself well for SIMD processing.",
            "-    for sb in (18..sb_end).step_by(18) {",
            "+    for sb in (18..channel.rzero).step_by(18) {",
            "         for i in 0..8 {",
            "             let li = sb - 1 - i;",
            "             let ui = sb + i;",
            "             let lower = samples[li];",
            "             let upper = samples[ui];",
            "             samples[li] = lower * cs[i] - upper * ca[i];",
            "             samples[ui] = upper * cs[i] + lower * ca[i];",
            "@@ -269,84 +278,91 @@",
            " ",
            " /// Performs hybrid synthesis (IMDCT and windowing).",
            " pub(super) fn hybrid_synthesis(",
            "     channel: &GranuleChannel,",
            "     overlap: &mut [[f32; 18]; 32],",
            "     samples: &mut [f32; 576],",
            " ) {",
            "-    // Determine the number of sub-bands to process as long blocks. Short blocks process 0 sub-bands",
            "-    // as long blocks, mixed blocks process the first 2 sub-bands as long blocks, and all other",
            "-    // block types (long, start, end) process all 32 sub-bands as long blocks.",
            "-    let n_long_bands = match channel.block_type {",
            "+    // The first sub-band after the rzero partition boundary is the sub-band limit. All sub-bands",
            "+    // past this are zeroed.",
            "+    let sb_limit = (channel.rzero + 17) / 18;",
            "+",
            "+    // Determine the split point of long and short blocks in terms of a sub-band index.",
            "+    //",
            "+    // Short blocks process 0 sub-bands as long blocks, mixed blocks process the first 2 sub-bands",
            "+    // as long blocks, and all other block types (long, start, end) process all 32 sub-bands as long",
            "+    // blocks.",
            "+    let sb_split = match channel.block_type {",
            "         BlockType::Short { is_mixed: false } => 0,",
            "         BlockType::Short { is_mixed: true } => 2,",
            "         _ => 32,",
            "     };",
            " ",
            "-    // For sub-bands that are processed as long blocks, perform the 36-point IMDCT.",
            "-    if n_long_bands > 0 {",
            "-        let mut output = [0f32; 36];",
            "-",
            "+    // If the split point is not 0, then some sub-bands need to be processed as long blocks using",
            "+    // the 36-point IMDCT.",
            "+    if sb_split > 0 {",
            "         // Select the appropriate window given the block type.",
            "-        let window = match channel.block_type {",
            "+        let window: &[f32; 36] = match channel.block_type {",
            "             BlockType::Start => &IMDCT_WINDOWS[1],",
            "             BlockType::End => &IMDCT_WINDOWS[3],",
            "             _ => &IMDCT_WINDOWS[0],",
            "         };",
            " ",
            "-        // For each of the 32 sub-bands (18 samples each)...",
            "-        for sb in 0..n_long_bands {",
            "-            // casting to a know-size slice lets the compiler elide bounds checks",
            "+        let sb_long_end = sb_split.min(sb_limit);",
            "+",
            "+        // For each of the sub-bands (18 samples each) in the long block...",
            "+        for sb in 0..sb_long_end {",
            "             let start = 18 * sb;",
            "+",
            "+            // Casting to a slice of a known-size lets the compiler elide bounds checks.",
            "             let sub_band: &mut [f32; 18] = (&mut samples[start..(start + 18)]).try_into().unwrap();",
            " ",
            "             // Perform the 36-point on the entire sub-band.",
            "-            imdct36::imdct36(sub_band, &mut output);",
            "-",
            "-            // Overlap the lower half of the IMDCT output (values 0..18) with the upper values of",
            "-            // the IMDCT (values 18..36) of the /previous/ iteration of the IMDCT. While doing this",
            "-            // also apply the window.",
            "-            for i in 0..18 {",
            "-                sub_band[i] = overlap[sb][i] + (output[i] * window[i]);",
            "-                overlap[sb][i] = output[18 + i] * window[18 + i];",
            "-            }",
            "+            imdct36::imdct36(sub_band, window, &mut overlap[sb]);",
            "         }",
            "     }",
            " ",
            "-    // If there are any sub-bands remaining, process them as short blocks. For short blocks, the",
            "-    // 12-point IMDCT must be used on each window.",
            "-    if n_long_bands < 32 {",
            "+    // If the split point is less-than 32, then some sub-bands need to be processed as short blocks",
            "+    // using the 12-point IMDCT on each of the three windows.",
            "+    if sb_split < 32 {",
            "         // Select the short block window.",
            "-        let window = &IMDCT_WINDOWS[2];",
            "+        let window: &[f32; 36] = &IMDCT_WINDOWS[2];",
            "+",
            "+        let sb_short_begin = sb_split.min(sb_limit);",
            " ",
            "-        // For each of the remaining 32 sub-bands (18 samples each)...",
            "-        for sb in n_long_bands..32 {",
            "-            // casting to a know-size slice lets the compiler elide bounds checks",
            "+        // For each of the sub-bands (18 samples each) in the short block...",
            "+        for sb in sb_short_begin..sb_limit {",
            "             let start = 18 * sb;",
            "+",
            "+            // Casting to a slice of a known-size lets the compiler elide bounds checks.",
            "             let sub_band: &mut [f32; 18] = (&mut samples[start..(start + 18)]).try_into().unwrap();",
            " ",
            "             // Perform the 12-point IMDCT on each of the 3 short windows within the sub-band (6",
            "             // samples each).",
            "-            let mut output = [0f32; 36];",
            "-            imdct12_win(sub_band, window, &mut output);",
            "-",
            "-            // Overlap the lower half of the IMDCT output (values 0..18) with the upper values of",
            "-            // the IMDCT (values 18..36) of the /previous/ iteration of the IMDCT.",
            "-            for i in 0..18 {",
            "-                sub_band[i] = overlap[sb][i] + output[i];",
            "-                overlap[sb][i] = output[18 + i];",
            "-            }",
            "+            imdct12_win(sub_band, window, &mut overlap[sb]);",
            "         }",
            "     }",
            "+",
            "+    // Every sub-band after the the sub-band limit are zeroed, however, the overlap for that",
            "+    // sub-band may be non-zero. Therefore, copy it over.",
            "+    for sb in sb_limit..32 {",
            "+        let start = 18 * sb;",
            "+        let sub_band: &mut [f32; 18] = (&mut samples[start..(start + 18)]).try_into().unwrap();",
            "+",
            "+        sub_band.copy_from_slice(&overlap[sb]);",
            "+        overlap[sb].fill(0.0);",
            "+    }",
            " }",
            " ",
            " /// Performs the 12-point IMDCT, and windowing for each of the 3 short windows of a short block, and",
            " /// then overlap-adds the result.",
            "-fn imdct12_win(x: &[f32; 18], window: &[f32; 36], out: &mut [f32; 36]) {",
            "-    let cos12 = &IMDCT_HALF_COS_12;",
            "+fn imdct12_win(x: &mut [f32; 18], window: &[f32; 36], overlap: &mut [f32; 18]) {",
            "+    let cos12: &[[f32; 6]; 6] = &IMDCT_HALF_COS_12;",
            "+",
            "+    let mut tmp = [0.0; 36];",
            " ",
            "     for w in 0..3 {",
            "         for i in 0..3 {",
            "             // Compute the 12-point IMDCT for each of the 3 short windows using a half-size IMDCT",
            "             // followed by post-processing.",
            "             //",
            "             // In general, the IMDCT is defined as:",
            "@@ -415,20 +431,26 @@",
            "             // .             .            .            +-------------------------+             .",
            "             // .             .            .            .            .            .             .",
            "             //",
            "             // Since the 12-point IMDCT was decomposed into a half-size IMDCT and post-processing",
            "             // operations, and further split into left and right halves, each iteration of this loop",
            "             // produces 4 output samples.",
            " ",
            "-            out[6 + 6 * w + 3 - i - 1] += -yl * window[3 - i - 1];",
            "-            out[6 + 6 * w + i + 3] += yl * window[i + 3];",
            "-            out[6 + 6 * w + i + 6] += yr * window[i + 6];",
            "-            out[6 + 6 * w + 12 - i - 1] += yr * window[12 - i - 1];",
            "+            tmp[6 + 6 * w + 3 - i - 1] += -yl * window[3 - i - 1];",
            "+            tmp[6 + 6 * w + i + 3] += yl * window[i + 3];",
            "+            tmp[6 + 6 * w + i + 6] += yr * window[i + 6];",
            "+            tmp[6 + 6 * w + 12 - i - 1] += yr * window[12 - i - 1];",
            "         }",
            "     }",
            "+",
            "+    // Overlap-add.",
            "+    for i in 0..18 {",
            "+        x[i] = tmp[i] + overlap[i];",
            "+        overlap[i] = tmp[i + 18];",
            "+    }",
            " }",
            " ",
            " /// Inverts odd samples in odd sub-bands.",
            " pub fn frequency_inversion(samples: &mut [f32; 576]) {",
            "     // There are 32 sub-bands spanning 576 samples:",
            "     //",
            "     //        0    18    36    54    72    90   108       558    576",
            "@@ -486,18 +508,22 @@",
            "             0.0976, 0.9321, 0.6138, 0.0857, 0.0433, 0.4855, 0.2144, 0.8488, //",
            "             0.6889, 0.2983, 0.1957, 0.7037, 0.0052, 0.0197, 0.3188, 0.5123, //",
            "             0.2994, 0.7157,",
            "         ];",
            " ",
            "         let window = &IMDCT_WINDOWS[2];",
            " ",
            "+        let mut actual = TEST_VECTOR;",
            "+        let mut overlap = [0.0; 18];",
            "+        imdct12_win(&mut actual, window, &mut overlap);",
            "+",
            "         // The following block performs 3 analytical 12-point IMDCTs over the test vector, and then",
            "         // windows and overlaps the results to generate the final result.",
            "-        let actual_result = {",
            "-            let mut actual_result = [0f32; 36];",
            "+        let expected = {",
            "+            let mut expected = [0f32; 36];",
            " ",
            "             let mut x0 = [0f32; 6];",
            "             let mut x1 = [0f32; 6];",
            "             let mut x2 = [0f32; 6];",
            " ",
            "             for i in 0..6 {",
            "                 x0[i] = TEST_VECTOR[3 * i + 0];",
            "@@ -506,27 +532,25 @@",
            "             }",
            " ",
            "             let imdct0 = imdct12_analytical(&x0);",
            "             let imdct1 = imdct12_analytical(&x1);",
            "             let imdct2 = imdct12_analytical(&x2);",
            " ",
            "             for i in 0..12 {",
            "-                actual_result[6 + i] += imdct0[i] * window[i];",
            "-                actual_result[12 + i] += imdct1[i] * window[i];",
            "-                actual_result[18 + i] += imdct2[i] * window[i];",
            "+                expected[6 + i] += imdct0[i] * window[i];",
            "+                expected[12 + i] += imdct1[i] * window[i];",
            "+                expected[18 + i] += imdct2[i] * window[i];",
            "             }",
            " ",
            "-            actual_result",
            "+            expected",
            "         };",
            " ",
            "-        let mut test_result = [0f32; 36];",
            "-        imdct12_win(&TEST_VECTOR, window, &mut test_result);",
            "-",
            "-        for i in 0..36 {",
            "-            assert!((actual_result[i] - test_result[i]).abs() < 0.00001);",
            "+        for i in 0..18 {",
            "+            assert!((expected[i] - actual[i]).abs() < 0.00001);",
            "+            assert!((expected[i + 18] - overlap[i]).abs() < 0.00001);",
            "         }",
            "     }",
            " }",
            " ",
            " mod imdct36 {",
            "     /// Performs an Inverse Modified Discrete Cosine Transform (IMDCT) transforming 18",
            "     /// frequency-domain input samples, into 36 time-domain output samples.",
            "@@ -535,39 +559,45 @@",
            "     /// published in article [1].",
            "     ///",
            "     /// [1] Szu-Wei Lee, \"Improved algorithm for efficient computation of the forward and backward",
            "     /// MDCT in MPEG audio coder\", IEEE Transactions on Circuits and Systems II: Analog and Digital",
            "     /// Signal Processing, vol. 48, no. 10, pp. 990-994, 2001.",
            "     ///",
            "     /// https://ieeexplore.ieee.org/document/974789",
            "-    pub fn imdct36(x: &[f32; 18], y: &mut [f32; 36]) {",
            "+    pub fn imdct36(x: &mut [f32; 18], window: &[f32; 36], overlap: &mut [f32; 18]) {",
            "         let mut dct = [0f32; 18];",
            " ",
            "         dct_iv(x, &mut dct);",
            " ",
            "         // Mapping of DCT-IV to IMDCT",
            "         //",
            "         //  0            9                       27           36",
            "         //  +------------+------------------------+------------+",
            "         //  | dct[9..18] | -dct[0..18].rev()      | -dct[0..9] |",
            "         //  +------------+------------------------+------------+",
            "         //",
            "         // where dct[] is the DCT-IV of x.",
            " ",
            "         // First 9 IMDCT values are values 9..18 in the DCT-IV.",
            "-        y[..9].copy_from_slice(&dct[9..(9 + 9)]);",
            "+        for i in 0..9 {",
            "+            x[i] = overlap[i] + dct[9 + i] * window[i];",
            "+        }",
            " ",
            "         // Next 18 IMDCT values are negated and /reversed/ values 0..18 in the DCT-IV.",
            "-        for i in 9..27 {",
            "-            y[i] = -dct[27 - i - 1];",
            "+        for i in 9..18 {",
            "+            x[i] = overlap[i] - dct[27 - i - 1] * window[i];",
            "+        }",
            "+",
            "+        for i in 18..27 {",
            "+            overlap[i - 18] = -dct[27 - i - 1] * window[i];",
            "         }",
            " ",
            "         // Last 9 IMDCT values are negated values 0..9 in the DCT-IV.",
            "         for i in 27..36 {",
            "-            y[i] = -dct[i - 27];",
            "+            overlap[i - 18] = -dct[i - 27] * window[i];",
            "         }",
            "     }",
            " ",
            "     /// Continutation of `imdct36`.",
            "     ///",
            "     /// Step 2: Mapping N/2-point DCT-IV to N/2-point SDCT-II.",
            "     fn dct_iv(x: &[f32; 18], y: &mut [f32; 18]) {",
            "@@ -768,17 +798,22 @@",
            "         fn verify_imdct36() {",
            "             const TEST_VECTOR: [f32; 18] = [",
            "                 0.0976, 0.9321, 0.6138, 0.0857, 0.0433, 0.4855, 0.2144, 0.8488, //",
            "                 0.6889, 0.2983, 0.1957, 0.7037, 0.0052, 0.0197, 0.3188, 0.5123, //",
            "                 0.2994, 0.7157,",
            "             ];",
            " ",
            "-            let mut test_result = [0f32; 36];",
            "-            imdct36(&TEST_VECTOR, &mut test_result);",
            "+            const WINDOW: [f32; 36] = [1.0; 36];",
            " ",
            "-            let actual_result = imdct36_analytical(&TEST_VECTOR);",
            "-            for i in 0..36 {",
            "-                assert!((actual_result[i] - test_result[i]).abs() < 0.00001);",
            "+            let mut actual = TEST_VECTOR;",
            "+            let mut overlap = [0.0; 18];",
            "+            imdct36(&mut actual, &WINDOW, &mut overlap);",
            "+",
            "+            let expected = imdct36_analytical(&TEST_VECTOR);",
            "+",
            "+            for i in 0..18 {",
            "+                assert!((expected[i] - actual[i]).abs() < 0.00001);",
            "+                assert!((expected[i + 18] - overlap[i]).abs() < 0.00001);",
            "             }",
            "         }",
            "     }",
            " }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/mod.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-mp3/src/layer3/mod.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/mod.rs",
            "@@ -436,20 +436,25 @@",
            "             // Each granule will yield 576 samples. After reserving frames, all steps must be",
            "             // infalliable.",
            "             out.render_reserved(Some(576));",
            " ",
            "             // The next steps are independant of channel count.",
            "             for ch in 0..header.n_channels() {",
            "                 // Reorder the spectral samples in short blocks into sub-band order.",
            "-                hybrid_synthesis::reorder(header, &granule.channels[ch], &mut self.samples[gr][ch]);",
            "+                hybrid_synthesis::reorder(",
            "+                    header,",
            "+                    &mut granule.channels[ch],",
            "+                    &mut self.samples[gr][ch],",
            "+                );",
            " ",
            "                 // Apply the anti-aliasing filter to all block types other than short.",
            "-                hybrid_synthesis::antialias(&granule.channels[ch], &mut self.samples[gr][ch]);",
            "+                hybrid_synthesis::antialias(&mut granule.channels[ch], &mut self.samples[gr][ch]);",
            " ",
            "-                // Perform hybrid-synthesis (IMDCT and windowing).",
            "+                // Perform hybrid-synthesis (IMDCT and windowing). After this step, rzero is invalid",
            "+                // due to the overlap-add operation.",
            "                 hybrid_synthesis::hybrid_synthesis(",
            "                     &granule.channels[ch],",
            "                     &mut self.overlap[ch],",
            "                     &mut self.samples[gr][ch],",
            "                 );",
            " ",
            "                 // Invert every second sample in every second sub-band to negate the frequency"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/requantize.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-bundle-mp3/src/layer3/requantize.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-bundle-mp3/src/layer3/requantize.rs",
            "@@ -34,17 +34,15 @@",
            "         pow43",
            "     };",
            " }",
            " ",
            " /// Zero a sample buffer.",
            " #[inline(always)]",
            " pub(super) fn zero(buf: &mut [f32; 576]) {",
            "-    for s in buf.iter_mut() {",
            "-        *s = 0.0;",
            "-    }",
            "+    buf.fill(0.0);",
            " }",
            " ",
            " /// Reads the Huffman coded spectral samples for a given channel in a granule from a `BitStream`",
            " /// into a provided sample buffer. Returns the number of decoded samples (the starting index of the",
            " /// rzero partition).",
            " ///",
            " /// Note, each spectral sample is raised to the (4/3)-rd power. This is not actually part of the",
            "@@ -54,15 +52,15 @@",
            "     bs: &mut B,",
            "     channel: &GranuleChannel,",
            "     part3_bits: u32,",
            "     buf: &mut [f32; 576],",
            " ) -> Result<usize> {",
            "     // If there are no Huffman code bits, zero all samples and return immediately.",
            "     if part3_bits == 0 {",
            "-        zero(buf);",
            "+        buf.fill(0.0);",
            "         return Ok(0);",
            "     }",
            " ",
            "     // Dereference the POW43 table once per granule since there is a tiny overhead each time a",
            "     // lazy_static is dereferenced that should be amortized over as many samples as possible.",
            "     let pow43_table: &[f32; 8207] = &REQUANTIZE_POW43;",
            " ",
            "@@ -233,18 +231,15 @@",
            "         // It seems that most other decoders don't undo overruns of the big values. We'll just print",
            "         // a message for now.",
            "         info!(\"big_values overrun, malformed bitstream\");",
            "     }",
            " ",
            "     // The final partition after the count1 partition is the rzero partition. Samples in this",
            "     // partition are all 0.",
            "-    for j in (i..576).step_by(2) {",
            "-        buf[j + 0] = 0.0;",
            "-        buf[j + 1] = 0.0;",
            "-    }",
            "+    buf[i..].fill(0.0);",
            " ",
            "     Ok(i)",
            " }",
            " ",
            " /// Requantize long block samples in `buf`.",
            " fn requantize_long(channel: &GranuleChannel, bands: &[usize], buf: &mut [f32; 576]) {",
            "     // For long blocks dequantization and scaling is governed by the following equation:"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-aac/src/aac/codebooks.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-aac/src/aac/codebooks.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-aac/src/aac/codebooks.rs",
            "@@ -560,15 +560,15 @@",
            " /// generate a codebook.",
            " fn make_raw_codebook(table: &VlcTable) -> Codebook<Entry16x16> {",
            "     assert_eq!(table.codes.len(), table.lens.len());",
            " ",
            "     let len = table.codes.len() as u16;",
            " ",
            "     // Generate the indicies for each code.",
            "-    let indicies: Vec<u16> = (0..len).into_iter().collect();",
            "+    let indicies: Vec<u16> = (0..len).collect();",
            " ",
            "     // Generate the codebook.",
            "     let mut builder = CodebookBuilder::new(BitOrder::Verbatim);",
            " ",
            "     // Read in 8-bit blocks.",
            "     builder.bits_per_read(8);",
            " ",
            "@@ -581,15 +581,15 @@",
            " where",
            "     C: MakeValueCodebook,",
            "     F: Fn(usize) -> C::ValueType,",
            " {",
            "     let codebook = make_raw_codebook(table);",
            " ",
            "     // Generate values for the codebook.",
            "-    let values: Vec<C::ValueType> = (0..table.codes.len()).into_iter().map(f).collect();",
            "+    let values: Vec<C::ValueType> = (0..table.codes.len()).map(f).collect();",
            " ",
            "     C::new(codebook, values.into_boxed_slice())",
            " }",
            " ",
            " /// Generate a codebook without any stored values.",
            " fn make_basic_codebook<C>(table: &VlcTable) -> C",
            " where",
            "@@ -652,15 +652,15 @@",
            " lazy_static! {",
            "     pub static ref SCALEFACTORS: Codebook<Entry8x16> = {",
            "         assert_eq!(SCF_CODEBOOK_CODES.len(), SCF_CODEBOOK_LENS.len());",
            " ",
            "         let len = SCF_CODEBOOK_CODES.len() as u8;",
            " ",
            "         // Generate the values for the codebook.",
            "-        let values: Vec<u8> = (0..len).into_iter().collect();",
            "+        let values: Vec<u8> = (0..len).collect();",
            " ",
            "         // Generate the codebook.",
            "         let mut builder = CodebookBuilder::new(BitOrder::Verbatim);",
            " ",
            "         // Read in 8-bit blocks.",
            "         builder.bits_per_read(8);"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-aac/src/aac/dsp.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-aac/src/aac/dsp.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-aac/src/aac/dsp.rs",
            "@@ -74,20 +74,20 @@",
            "         };",
            " ",
            "         // Inverse MDCT",
            "         if seq != EIGHT_SHORT_SEQUENCE {",
            "             self.imdct_long.imdct(coeffs, &mut self.pcm_long);",
            "         }",
            "         else {",
            "-            for (ain, aout) in coeffs.chunks_exact(128).zip(self.pcm_long.chunks_mut(256)) {",
            "+            for (ain, aout) in coeffs.chunks_exact(128).zip(self.pcm_long.chunks_exact_mut(256)) {",
            "                 self.imdct_short.imdct(ain, aout);",
            "             }",
            " ",
            "             // Zero the eight short sequence buffer.",
            "-            self.pcm_short = [0.0; 1152];",
            "+            self.pcm_short.fill(0.0);",
            " ",
            "             for (w, src) in self.pcm_long.chunks_exact(256).enumerate() {",
            "                 if w > 0 {",
            "                     for i in 0..128 {",
            "                         self.pcm_short[w * 128 + i] += src[i] * short_win[i];",
            "                         self.pcm_short[w * 128 + i + 128] += src[i + 128] * short_win[127 - i];",
            "                     }",
            "@@ -136,26 +136,24 @@",
            "                 }",
            "             }",
            "             EIGHT_SHORT_SEQUENCE => {",
            "                 for i in 0..SHORT_WIN_POINT1 {",
            "                     // Last part is already windowed.",
            "                     delay[i] = self.pcm_short[i + 512 + 64];",
            "                 }",
            "-                for i in SHORT_WIN_POINT1..1024 {",
            "-                    delay[i] = 0.0;",
            "-                }",
            "+",
            "+                delay[SHORT_WIN_POINT1..].fill(0.0);",
            "             }",
            "             LONG_START_SEQUENCE => {",
            "                 delay[..SHORT_WIN_POINT0]",
            "                     .copy_from_slice(&self.pcm_long[1024..(SHORT_WIN_POINT0 + 1024)]);",
            " ",
            "                 for i in SHORT_WIN_POINT0..SHORT_WIN_POINT1 {",
            "                     delay[i] = self.pcm_long[i + 1024] * short_win[127 - (i - SHORT_WIN_POINT0)];",
            "                 }",
            "-                for i in SHORT_WIN_POINT1..1024 {",
            "-                    delay[i] = 0.0;",
            "-                }",
            "+",
            "+                delay[SHORT_WIN_POINT1..].fill(0.0);",
            "             }",
            "             _ => unreachable!(),",
            "         };",
            "     }",
            " }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-aac/src/aac/ics/mod.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-aac/src/aac/ics/mod.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-aac/src/aac/ics/mod.rs",
            "@@ -8,14 +8,15 @@",
            " // and ported to the Symphonia project.",
            " //",
            " // This Source Code Form is subject to the terms of the Mozilla Public",
            " // License, v. 2.0. If a copy of the MPL was not distributed with this",
            " // file, You can obtain one at https://mozilla.org/MPL/2.0/.",
            " ",
            " use symphonia_core::errors::{decode_error, Result};",
            "+use symphonia_core::io::vlc::{Codebook, Entry8x16};",
            " use symphonia_core::io::ReadBitsLtr;",
            " ",
            " use crate::aac::codebooks;",
            " use crate::aac::common::*;",
            " use crate::aac::dsp;",
            " use crate::common::M4AType;",
            " ",
            "@@ -29,25 +30,54 @@",
            " ",
            " const ZERO_HCB: u8 = 0;",
            " const RESERVED_HCB: u8 = 12;",
            " const NOISE_HCB: u8 = 13;",
            " const INTENSITY_HCB2: u8 = 14;",
            " const INTENSITY_HCB: u8 = 15;",
            " ",
            "+const INTENSITY_SCALE_MIN: i16 = -155;",
            "+const NORMAL_SCALE_MIN: i16 = -100;",
            "+",
            " lazy_static! {",
            "     /// Pre-computed table of y = x^(4/3).",
            "     static ref POW43_TABLE: [f32; 8192] = {",
            "         let mut pow43 = [0f32; 8192];",
            "         for (i, pow43) in pow43.iter_mut().enumerate() {",
            "             *pow43 = f32::powf(i as f32, 4.0 / 3.0);",
            "         }",
            "         pow43",
            "     };",
            " }",
            " ",
            "+lazy_static! {",
            "+    /// Pre-computed table of y = 2^(0.25 * (x - 156)) for decoding scale factors for normal bands.",
            "+    /// This table is indexed relative to -100, the minimum encoded scale factor value for normal",
            "+    /// bands. Therefore, an input of 0 corresponds to -100.",
            "+    static ref NORMAL_SCF_TABLE: [f32; 256] = {",
            "+        let mut table = [0f32; 256];",
            "+        for (i, table) in table.iter_mut().enumerate() {",
            "+            *table = 2.0f32.powf(0.25 * f32::from(i as i16 - 56 + NORMAL_SCALE_MIN))",
            "+        }",
            "+        table",
            "+    };",
            "+}",
            "+",
            "+lazy_static! {",
            "+    /// Pre-computed table of y = 0.5^(0.25 * (x - 155)) for decoding scale factors for intensity",
            "+    /// coded bands. This table is indexed relative to -155, the minimum encoded scale factor value",
            "+    /// for intensity coded bands. Therefore, an input of 0 corresponds to -155.",
            "+    static ref INTENSITY_SCF_TABLE: [f32; 256] = {",
            "+        let mut table = [0f32; 256];",
            "+        for (i, table) in table.iter_mut().enumerate() {",
            "+            *table = 0.5f32.powf(0.25 * f32::from(i as i16 + INTENSITY_SCALE_MIN));",
            "+        }",
            "+        table",
            "+    };",
            "+}",
            "+",
            " #[derive(Clone)]",
            " pub struct IcsInfo {",
            "     pub window_sequence: u8,",
            "     pub prev_window_sequence: u8,",
            "     pub window_shape: bool,",
            "     pub prev_window_shape: bool,",
            "     pub scale_factor_grouping: [bool; MAX_WINDOWS],",
            "@@ -172,28 +202,14 @@",
            "     num_sec: [usize; MAX_WINDOWS],",
            "     pub scales: [[f32; MAX_SFBS]; MAX_WINDOWS],",
            "     sbinfo: GASubbandInfo,",
            "     pub coeffs: [f32; 1024],",
            "     delay: [f32; 1024],",
            " }",
            " ",
            "-const INTENSITY_SCALE_MIN: i16 = -155;",
            "-const NOISE_SCALE_MIN: i16 = -100;",
            "-",
            "-#[inline(always)]",
            "-fn get_scale(scale: i16) -> f32 {",
            "-    2.0f32.powf(0.25 * f32::from(scale - 56))",
            "-    // 2.0f32.powf(0.25 * (f32::from(scale) - 100.0 - 56.0))",
            "-}",
            "-",
            "-#[inline(always)]",
            "-fn get_intensity_scale(scale: i16) -> f32 {",
            "-    0.5f32.powf(0.25 * f32::from(scale))",
            "-}",
            "-",
            " impl Ics {",
            "     pub fn new(sbinfo: GASubbandInfo) -> Self {",
            "         Self {",
            "             global_gain: 0,",
            "             info: IcsInfo::new(),",
            "             pulse: None,",
            "             tns: None,",
            "@@ -273,55 +289,57 @@",
            "     #[inline(always)]",
            "     pub fn get_intensity_dir(&self, g: usize, sfb: usize) -> bool {",
            "         self.sfb_cb[g][sfb] == INTENSITY_HCB",
            "     }",
            " ",
            "     fn decode_scale_factor_data<B: ReadBitsLtr>(&mut self, bs: &mut B) -> Result<()> {",
            "         let mut noise_pcm_flag = true;",
            "-        let mut scf_intensity = 0i16;",
            "-        let mut scf_noise = i16::from(self.global_gain) - 90;",
            "+        let mut scf_intensity = -INTENSITY_SCALE_MIN;",
            "+        let mut scf_noise = i16::from(self.global_gain) - 90 - NORMAL_SCALE_MIN;",
            "         let mut scf_normal = i16::from(self.global_gain);",
            " ",
            "-        let scf_cb = &codebooks::SCALEFACTORS;",
            "+        let scf_cb: &Codebook<Entry8x16> = &codebooks::SCALEFACTORS;",
            "+",
            "+        let table_normal_scf: &[f32; 256] = &NORMAL_SCF_TABLE;",
            "+        let table_intensity_scf: &[f32; 256] = &INTENSITY_SCF_TABLE;",
            " ",
            "         for g in 0..self.info.window_groups {",
            "             for sfb in 0..self.info.max_sfb {",
            "                 self.scales[g][sfb] = if self.is_zero(g, sfb) {",
            "                     0.0",
            "                 }",
            "                 else if self.is_intensity(g, sfb) {",
            "                     scf_intensity += i16::from(bs.read_codebook(scf_cb)?.0) - 60;",
            " ",
            "-                    validate!(",
            "-                        (scf_intensity >= INTENSITY_SCALE_MIN)",
            "-                            && (scf_intensity < INTENSITY_SCALE_MIN + 256)",
            "-                    );",
            "+                    // Valid range is -155 to 100. Value offset by 155 for lookup table indexing.",
            "+                    validate!((scf_intensity >= 0) && (scf_intensity < 256));",
            " ",
            "-                    get_intensity_scale(scf_intensity)",
            "+                    table_intensity_scf[scf_intensity as usize]",
            "                 }",
            "                 else if self.is_noise(g, sfb) {",
            "                     if noise_pcm_flag {",
            "                         noise_pcm_flag = false;",
            "                         scf_noise += (bs.read_bits_leq32(9)? as i16) - 256;",
            "                     }",
            "                     else {",
            "                         scf_noise += i16::from(bs.read_codebook(scf_cb)?.0) - 60;",
            "                     }",
            " ",
            "-                    validate!(",
            "-                        (scf_noise >= NOISE_SCALE_MIN) && (scf_noise < NOISE_SCALE_MIN + 256)",
            "-                    );",
            "+                    // Valid range is -100 to 155. Value offset by 100 for lookup table indexing.",
            "+                    validate!((scf_noise >= 0) && (scf_noise < 256));",
            " ",
            "-                    get_scale(scf_noise)",
            "+                    table_normal_scf[scf_noise as usize]",
            "                 }",
            "                 else {",
            "                     scf_normal += i16::from(bs.read_codebook(scf_cb)?.0) - 60;",
            "+",
            "+                    // Valid range is -100 to 155. Value offset by 100 for lookup table indexing.",
            "                     validate!((scf_normal >= 0) && (scf_normal < 256));",
            " ",
            "-                    get_scale(scf_normal - 100)",
            "+                    table_normal_scf[scf_normal as usize]",
            "                 }",
            "             }",
            "         }",
            "         Ok(())",
            "     }",
            " ",
            "     pub fn get_bands(&self) -> &'static [usize] {",
            "@@ -331,15 +349,15 @@",
            "         else {",
            "             self.sbinfo.short_bands",
            "         }",
            "     }",
            " ",
            "     fn decode_spectrum<B: ReadBitsLtr>(&mut self, bs: &mut B, lcg: &mut Lcg) -> Result<()> {",
            "         // Zero all spectral coefficients.",
            "-        self.coeffs = [0.0; 1024];",
            "+        self.coeffs.fill(0.0);",
            " ",
            "         let bands = self.get_bands();",
            " ",
            "         for g in 0..self.info.window_groups {",
            "             let cur_w = self.info.get_group_start(g);",
            "             let next_w = self.info.get_group_start(g + 1);",
            "             for sfb in 0..self.info.max_sfb {"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-adpcm/src/codec_ima.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-adpcm/src/codec_ima.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-adpcm/src/codec_ima.rs",
            "@@ -1,15 +1,15 @@",
            " // Symphonia",
            " // Copyright (c) 2019-2022 The Project Symphonia Developers.",
            " //",
            " // This Source Code Form is subject to the terms of the Mozilla Public",
            " // License, v. 2.0. If a copy of the MPL was not distributed with this",
            " // file, You can obtain one at https://mozilla.org/MPL/2.0/.",
            " ",
            "-use symphonia_core::errors::Result;",
            "+use symphonia_core::errors::{decode_error, Result};",
            " use symphonia_core::io::ReadBytes;",
            " use symphonia_core::util::clamp::clamp_i16;",
            " ",
            " use crate::common::{from_i16_shift, u16_to_i32, Nibble};",
            " ",
            " #[rustfmt::skip]",
            " const IMA_INDEX_TABLE: [i32; 16] = [",
            "@@ -36,14 +36,17 @@",
            "     step_index: i32,",
            " }",
            " ",
            " impl AdpcmImaBlockStatus {",
            "     fn read_preamble<B: ReadBytes>(stream: &mut B) -> Result<Self> {",
            "         let predictor = u16_to_i32!(stream.read_u16()?);",
            "         let step_index = stream.read_byte()? as i32;",
            "+        if step_index > 88 {",
            "+            return decode_error(\"adpcm (ima): invalid step index\");",
            "+        }",
            "         //reserved byte",
            "         let _ = stream.read_byte()?;",
            "         let status = Self { predictor, step_index };",
            "         Ok(status)",
            "     }",
            " ",
            "     fn expand_nibble(&mut self, byte: u8, nibble: Nibble) -> i32 {"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-pcm/src/lib.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-pcm/src/lib.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-pcm/src/lib.rs",
            "@@ -26,15 +26,15 @@",
            " // Unsigned Int PCM codecs",
            " use symphonia_core::codecs::{CODEC_TYPE_PCM_U16BE, CODEC_TYPE_PCM_U24BE, CODEC_TYPE_PCM_U32BE};",
            " use symphonia_core::codecs::{CODEC_TYPE_PCM_U16LE, CODEC_TYPE_PCM_U8};",
            " use symphonia_core::codecs::{CODEC_TYPE_PCM_U24LE, CODEC_TYPE_PCM_U32LE};",
            " // Floating point PCM codecs",
            " use symphonia_core::codecs::{CODEC_TYPE_PCM_F32BE, CODEC_TYPE_PCM_F32LE};",
            " use symphonia_core::codecs::{CODEC_TYPE_PCM_F64BE, CODEC_TYPE_PCM_F64LE};",
            "-// G711 ALaw and MuLaw PCM cdoecs.",
            "+// G711 ALaw and MuLaw PCM codecs",
            " use symphonia_core::codecs::{CODEC_TYPE_PCM_ALAW, CODEC_TYPE_PCM_MULAW};",
            " use symphonia_core::conv::IntoSample;",
            " use symphonia_core::errors::{decode_error, unsupported_error, Result};",
            " use symphonia_core::formats::Packet;",
            " use symphonia_core::io::ReadBytes;",
            " use symphonia_core::sample::{i24, u24, SampleFormat};",
            " use symphonia_core::units::Duration;",
            "@@ -169,15 +169,41 @@",
            "             }",
            "             _ => unreachable!(),",
            "         }",
            "     };",
            " }",
            " ",
            " // alaw_to_linear and mulaw_to_linear are adaptations of alaw2linear and ulaw2linear from g711.c by",
            "-// SUN Microsystems (unrestricted use license).",
            "+// SUN Microsystems (unrestricted use license), license text for these parts follow below.",
            "+//",
            "+// ---",
            "+//",
            "+// This source code is a product of Sun Microsystems, Inc. and is provided for",
            "+// unrestricted use.  Users may copy or modify this source code without",
            "+// charge.",
            "+//",
            "+// SUN SOURCE CODE IS PROVIDED AS IS WITH NO WARRANTIES OF ANY KIND INCLUDING THE",
            "+// WARRANTIES OF DESIGN, MERCHANTIBILITY AND FITNESS FOR A PARTICULAR",
            "+// PURPOSE, OR ARISING FROM A COURSE OF DEALING, USAGE OR TRADE PRACTICE.",
            "+//",
            "+// Sun source code is provided with no support and without any obligation on the",
            "+// part of Sun Microsystems, Inc. to assist in its use, correction,",
            "+// modification or enhancement.",
            "+//",
            "+// SUN MICROSYSTEMS, INC. SHALL HAVE NO LIABILITY WITH RESPECT TO THE",
            "+// INFRINGEMENT OF COPYRIGHTS, TRADE SECRETS OR ANY PATENTS BY THIS SOFTWARE",
            "+// OR ANY PART THEREOF.",
            "+//",
            "+// In no event will Sun Microsystems, Inc. be liable for any lost revenue",
            "+// or profits or other special, indirect and consequential damages, even if",
            "+// Sun has been advised of the possibility of such damages.",
            "+//",
            "+// Sun Microsystems, Inc.",
            "+// 2550 Garcia Avenue",
            "+// Mountain View, California  94043",
            " const XLAW_QUANT_MASK: u8 = 0x0f;",
            " const XLAW_SEG_MASK: u8 = 0x70;",
            " const XLAW_SEG_SHIFT: u32 = 4;",
            " ",
            " fn alaw_to_linear(mut a_val: u8) -> i16 {",
            "     a_val ^= 0x55;"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-vorbis/src/codebook.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-vorbis/src/codebook.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-vorbis/src/codebook.rs",
            "@@ -350,15 +350,15 @@",
            "         };",
            " ",
            "         // Generate a canonical list of codewords given the set of codeword lengths.",
            "         let code_words = synthesize_codewords(&code_lens)?;",
            " ",
            "         // Generate the values associated for each codeword.",
            "         // TODO: Should unused entries be 0 or actually the correct value?",
            "-        let values: Vec<u32> = (0..codebook_entries).into_iter().collect();",
            "+        let values: Vec<u32> = (0..codebook_entries).collect();",
            " ",
            "         // Finally, generate the codebook with a reverse (LSb) bit order.",
            "         let mut builder = CodebookBuilder::new_sparse(BitOrder::Reverse);",
            " ",
            "         // Read in 8-bit blocks.",
            "         builder.bits_per_read(8);"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-vorbis/src/lib.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-vorbis/src/lib.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-vorbis/src/lib.rs",
            "@@ -560,15 +560,15 @@",
            "     (0..count).map(|_| read_residue(bs, max_codebook)).collect()",
            " }",
            " ",
            " fn read_residue(bs: &mut BitReaderRtl<'_>, max_codebook: u8) -> Result<Residue> {",
            "     let residue_type = bs.read_bits_leq32(16)? as u16;",
            " ",
            "     match residue_type {",
            "-        0 | 1 | 2 => Residue::try_read(bs, residue_type, max_codebook),",
            "+        0..=2 => Residue::try_read(bs, residue_type, max_codebook),",
            "         _ => decode_error(\"vorbis: invalid residue type\"),",
            "     }",
            " }",
            " ",
            " fn read_mappings(",
            "     bs: &mut BitReaderRtl<'_>,",
            "     audio_channels: u8,"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-codec-vorbis/src/residue.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-codec-vorbis/src/residue.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-codec-vorbis/src/residue.rs",
            "@@ -139,173 +139,266 @@",
            "         &mut self,",
            "         bs: &mut BitReaderRtl<'_>,",
            "         bs_exp: u8,",
            "         codebooks: &[VorbisCodebook],",
            "         residue_channels: &BitSet256,",
            "         channels: &mut [DspChannel],",
            "     ) -> Result<()> {",
            "+        let result = if self.setup.residue_type == 2 {",
            "+            self.read_residue_inner_type_2(bs, bs_exp, codebooks, residue_channels, channels)",
            "+        }",
            "+        else {",
            "+            self.read_residue_inner_type_0_1(bs, bs_exp, codebooks, residue_channels, channels)",
            "+        };",
            "+",
            "         // Read the residue, and ignore end-of-bitstream errors which are legal.",
            "-        match self.read_residue_inner(bs, bs_exp, codebooks, residue_channels, channels) {",
            "+        match result {",
            "             Ok(_) => (),",
            "             // An end-of-bitstream error is classified under ErrorKind::Other. This condition",
            "             // should not be treated as an error.",
            "             Err(Error::IoError(ref e)) if e.kind() == io::ErrorKind::Other => (),",
            "             Err(e) => return Err(e),",
            "         };",
            " ",
            "+        // For format 2, the residue vectors for all channels are interleaved together into one",
            "+        // large vector. This vector is in the scratch-pad buffer and can now be de-interleaved",
            "+        // into the channel buffers.",
            "         if self.setup.residue_type == 2 {",
            "-            // For format 2, the residue vectors for all channels are interleaved together into one",
            "-            // large vector. This vector is in the scratch-pad buffer and can now be de-interleaved",
            "-            // into the channel buffers.",
            "-            let stride = residue_channels.count();",
            "+            self.deinterleave_2(residue_channels, channels);",
            "+        }",
            " ",
            "-            for (i, ch) in residue_channels.iter().enumerate() {",
            "-                let channel = &mut channels[ch];",
            "+        Ok(())",
            "+    }",
            " ",
            "-                let iter = self.type2_buf.chunks_exact(stride).map(|c| c[i]);",
            "+    /// Deinterleave samples from the type 2 format buffer into channel buffers.",
            "+    fn deinterleave_2(&mut self, residue_channels: &BitSet256, channels: &mut [DspChannel]) {",
            "+        match residue_channels.count() {",
            "+            2 => {",
            "+                // Two channel deinterleave.",
            "+                let (ch0, ch1) = {",
            "+                    let mut iter = residue_channels.iter();",
            "+",
            "+                    // Get indicies of first two channels in the residue.",
            "+                    let ch0 = iter.next().unwrap();",
            "+                    let ch1 = iter.next().unwrap();",
            "+",
            "+                    // Get references to the channels.",
            "+                    let (a, b) = channels.split_at_mut(ch0).1.split_at_mut(ch1);",
            "+",
            "+                    (&mut a[0], &mut b[0])",
            "+                };",
            "+",
            "+                // Deinterleave.",
            "+                for ((buf, chan0), chan1) in self",
            "+                    .type2_buf",
            "+                    .chunks_exact(2)",
            "+                    .zip(ch0.residue.iter_mut())",
            "+                    .zip(ch1.residue.iter_mut())",
            "+                {",
            "+                    *chan0 = buf[0];",
            "+                    *chan1 = buf[1];",
            "+                }",
            "+            }",
            "+            stride => {",
            "+                // Generic deinterleave.",
            "+                for (i, ch) in residue_channels.iter().enumerate() {",
            "+                    let channel = &mut channels[ch];",
            " ",
            "-                for (o, i) in channel.residue.iter_mut().zip(iter) {",
            "-                    *o = i;",
            "+                    let iter = self.type2_buf.chunks_exact(stride).map(|c| c[i]);",
            "+",
            "+                    for (o, i) in channel.residue.iter_mut().zip(iter) {",
            "+                        *o = i;",
            "+                    }",
            "                 }",
            "             }",
            "         }",
            "-",
            "-        Ok(())",
            "     }",
            " ",
            "-    fn read_residue_inner(",
            "+    fn read_residue_inner_type_2(",
            "         &mut self,",
            "         bs: &mut BitReaderRtl<'_>,",
            "         bs_exp: u8,",
            "         codebooks: &[VorbisCodebook],",
            "         residue_channels: &BitSet256,",
            "         channels: &mut [DspChannel],",
            "     ) -> Result<()> {",
            "         let class_book = &codebooks[self.setup.residue_classbook as usize];",
            " ",
            "         // The actual length of the entire residue vector for a channel (formats 0 and 1), or all",
            "         // interleaved channels (format 2).",
            "-        let full_residue_len = match self.setup.residue_type {",
            "-            2 => ((1 << bs_exp) >> 1) * residue_channels.count(),",
            "-            _ => (1 << bs_exp) >> 1,",
            "-        };",
            "+        let full_residue_len = ((1 << bs_exp) >> 1) * residue_channels.count();",
            " ",
            "         // The range of the residue vector being decoded.",
            "         let limit_residue_begin = min(self.setup.residue_begin as usize, full_residue_len);",
            "         let limit_residue_end = min(self.setup.residue_end as usize, full_residue_len);",
            " ",
            "         // Length of the decoded part of the residue vector.",
            "         let residue_len = limit_residue_end - limit_residue_begin;",
            " ",
            "         // Number of partitions per classword.",
            "         let parts_per_classword = class_book.dimensions();",
            " ",
            "         // Number of partitions to read.",
            "         let parts_to_read = residue_len / self.setup.residue_partition_size as usize;",
            " ",
            "-        let is_fmt2 = self.setup.residue_type == 2;",
            "+        // Reserve partition classification space.",
            "+        self.prepare_partition_classes(parts_to_read);",
            " ",
            "-        // Setup the scratch-pad.",
            "-        if is_fmt2 {",
            "-            // Reserve partition classification space in the scratch-pad.",
            "-            self.setup_part_classes(parts_to_read);",
            "+        // Reserve the type 2 interleave buffer storage, and zero all samples.",
            "+        self.prepare_type_2_format_buffer(full_residue_len);",
            " ",
            "-            // Reserve interleave buffer storage in the scratch-pad.",
            "-            self.setup_type2_buf(full_residue_len);",
            "+        // If all channels are marked do-not-decode then exit immediately.",
            "+        let has_channel_to_decode =",
            "+            residue_channels.iter().fold(false, |val, ch| val | !channels[ch].do_not_decode);",
            "+",
            "+        if !has_channel_to_decode {",
            "+            return Ok(());",
            "         }",
            "-        else {",
            "-            self.setup_part_classes(parts_to_read * residue_channels.count());",
            "+",
            "+        let part_size = self.setup.residue_partition_size as usize;",
            "+",
            "+        // Residues may be encoded in up-to 8 passes. Fewer passes may be encoded by prematurely",
            "+        // \"ending\" the packet. This means that an end-of-bitstream error is actually NOT an error.",
            "+        for pass in 0..self.setup.residue_max_pass + 1 {",
            "+            // Iterate over the partitions in batches grouped by classword.",
            "+            for part_first in (0..parts_to_read).step_by(parts_per_classword as usize) {",
            "+                // The class assignments for each partition in the classword group are only",
            "+                // encoded in the first pass.",
            "+                if pass == 0 {",
            "+                    let code = class_book.read_scalar(bs)?;",
            "+",
            "+                    decode_classes(",
            "+                        code,",
            "+                        parts_per_classword,",
            "+                        self.setup.residue_classifications as u32,",
            "+                        &mut self.part_classes[part_first..],",
            "+                    );",
            "+                }",
            "+",
            "+                // The last partition in this batch of partitions, being careful not to exceed the",
            "+                // total number of partitions.",
            "+                let part_last = min(parts_to_read, part_first + parts_per_classword as usize);",
            "+",
            "+                // Iterate over all partitions belonging to the current classword group.",
            "+                for part in part_first..part_last {",
            "+                    let vq_class = &self.setup.residue_vq_class[self.part_classes[part] as usize];",
            "+",
            "+                    if vq_class.is_used(pass) {",
            "+                        let vq_book = &codebooks[vq_class.books[pass] as usize];",
            "+",
            "+                        let part_start = limit_residue_begin + part_size * part;",
            "+",
            "+                        // Residue type 2 is implemented in term of type 1.",
            "+                        read_residue_partition_format1(",
            "+                            bs,",
            "+                            vq_book,",
            "+                            &mut self.type2_buf[part_start..part_start + part_size],",
            "+                        )?;",
            "+                    }",
            "+                }",
            "+                // End of partition batch iteration.",
            "+            }",
            "+            // End of pass iteration.",
            "         }",
            " ",
            "+        Ok(())",
            "+    }",
            "+",
            "+    fn read_residue_inner_type_0_1(",
            "+        &mut self,",
            "+        bs: &mut BitReaderRtl<'_>,",
            "+        bs_exp: u8,",
            "+        codebooks: &[VorbisCodebook],",
            "+        residue_channels: &BitSet256,",
            "+        channels: &mut [DspChannel],",
            "+    ) -> Result<()> {",
            "+        let class_book = &codebooks[self.setup.residue_classbook as usize];",
            "+",
            "+        // The actual length of the entire residue vector for a channel (formats 0 and 1), or all",
            "+        // interleaved channels (format 2).",
            "+        let full_residue_len = (1 << bs_exp) >> 1;",
            "+",
            "+        // The range of the residue vector being decoded.",
            "+        let limit_residue_begin = min(self.setup.residue_begin as usize, full_residue_len);",
            "+        let limit_residue_end = min(self.setup.residue_end as usize, full_residue_len);",
            "+",
            "+        // Length of the decoded part of the residue vector.",
            "+        let residue_len = limit_residue_end - limit_residue_begin;",
            "+",
            "+        // Number of partitions per classword.",
            "+        let parts_per_classword = class_book.dimensions();",
            "+",
            "+        // Number of partitions to read.",
            "+        let parts_to_read = residue_len / self.setup.residue_partition_size as usize;",
            "+",
            "+        // Reserve partition classification space.",
            "+        self.prepare_partition_classes(parts_to_read * residue_channels.count());",
            "+",
            "         let mut has_channel_to_decode = false;",
            " ",
            "-        // Zero unused residue channels.",
            "         for ch in residue_channels.iter() {",
            "-            let channel = &mut channels[ch];",
            "-",
            "-            // Zero the channel residue if not type 2.",
            "-            if !is_fmt2 {",
            "-                channel.residue[..full_residue_len].fill(0.0);",
            "-            }",
            "+            // Record if the channel needs to be decoded.",
            "+            has_channel_to_decode |= !channels[ch].do_not_decode;",
            " ",
            "-            has_channel_to_decode |= !channel.do_not_decode;",
            "+            // Zero the channel residue buffer.",
            "+            channels[ch].residue[..full_residue_len].fill(0.0);",
            "         }",
            " ",
            "-        // If all channels are marked do-not-decode then immediately exit.",
            "+        // If all channels are marked do-not-decode then exit immediately.",
            "         if !has_channel_to_decode {",
            "             return Ok(());",
            "         }",
            " ",
            "         let part_size = self.setup.residue_partition_size as usize;",
            " ",
            "         // Residues may be encoded in up-to 8 passes. Fewer passes may be encoded by prematurely",
            "         // \"ending\" the packet. This means that an end-of-bitstream error is actually NOT an error.",
            "         for pass in 0..self.setup.residue_max_pass + 1 {",
            "             // Iterate over the partitions in batches grouped by classword.",
            "             for part_first in (0..parts_to_read).step_by(parts_per_classword as usize) {",
            "                 // The class assignments for each partition in the classword group are only",
            "                 // encoded in the first pass.",
            "                 if pass == 0 {",
            "-                    // If using format 2, there is only a single classification list.",
            "-                    if is_fmt2 {",
            "+                    for (i, ch) in residue_channels.iter().enumerate() {",
            "+                        let channel = &channels[ch];",
            "+",
            "+                        // If the channel is marked do-not-decode then advance to the next",
            "+                        // channel.",
            "+                        if channel.do_not_decode {",
            "+                            continue;",
            "+                        }",
            "+",
            "                         let code = class_book.read_scalar(bs)?;",
            " ",
            "                         decode_classes(",
            "                             code,",
            "                             parts_per_classword,",
            "                             self.setup.residue_classifications as u32,",
            "-                            &mut self.part_classes[part_first..],",
            "+                            &mut self.part_classes[part_first + i * parts_to_read..],",
            "                         );",
            "                     }",
            "-                    else {",
            "-                        // For formats 0 and 1, each channel has its own classification list.",
            "-                        for (i, ch) in residue_channels.iter().enumerate() {",
            "-                            let channel = &channels[ch];",
            "-",
            "-                            // If the channel is marked do-not-decode then advance to the next",
            "-                            // channel.",
            "-                            if channel.do_not_decode {",
            "-                                continue;",
            "-                            }",
            "-",
            "-                            let code = class_book.read_scalar(bs)?;",
            "-",
            "-                            decode_classes(",
            "-                                code,",
            "-                                parts_per_classword,",
            "-                                self.setup.residue_classifications as u32,",
            "-                                &mut self.part_classes[part_first + i * parts_to_read..],",
            "-                            );",
            "-                        }",
            "-                    }",
            "                 }",
            " ",
            "                 // The last partition in this batch of partitions, being careful not to exceed the",
            "                 // total number of partitions.",
            "                 let part_last = min(parts_to_read, part_first + parts_per_classword as usize);",
            " ",
            "                 // Iterate over all partitions belonging to the current classword group.",
            "                 for part in part_first..part_last {",
            "                     // Iterate over each channel vector in the partition.",
            "                     for (i, ch) in residue_channels.iter().enumerate() {",
            "                         let channel = &mut channels[ch];",
            " ",
            "-                        let vq_class = if !is_fmt2 {",
            "-                            // If the channel is marked do-no-decode, then advance to the next",
            "-                            // channels.",
            "-                            if channel.do_not_decode {",
            "-                                continue;",
            "-                            }",
            "-",
            "-                            let class_idx = self.part_classes[part + parts_to_read * i] as usize;",
            "-                            &self.setup.residue_vq_class[class_idx]",
            "+                        // If the channel is marked do-not-decode, then advance to the next channel.",
            "+                        if channel.do_not_decode {",
            "+                            continue;",
            "                         }",
            "-                        else {",
            "-                            &self.setup.residue_vq_class[self.part_classes[part] as usize]",
            "-                        };",
            "+",
            "+                        let class_idx = self.part_classes[part + parts_to_read * i] as usize;",
            "+                        let vq_class = &self.setup.residue_vq_class[class_idx];",
            " ",
            "                         if vq_class.is_used(pass) {",
            "                             let vq_book = &codebooks[vq_class.books[pass] as usize];",
            " ",
            "                             let part_start = limit_residue_begin + part_size * part;",
            " ",
            "                             match self.setup.residue_type {",
            "@@ -315,51 +408,39 @@",
            "                                     &mut channel.residue[part_start..part_start + part_size],",
            "                                 ),",
            "                                 1 => read_residue_partition_format1(",
            "                                     bs,",
            "                                     vq_book,",
            "                                     &mut channel.residue[part_start..part_start + part_size],",
            "                                 ),",
            "-                                2 => {",
            "-                                    // Residue type 2 is implemented in term of type 1.",
            "-                                    read_residue_partition_format1(",
            "-                                        bs,",
            "-                                        vq_book,",
            "-                                        &mut self.type2_buf[part_start..part_start + part_size],",
            "-                                    )",
            "-                                }",
            "                                 _ => unreachable!(),",
            "                             }?;",
            "                         }",
            "-",
            "-                        if is_fmt2 {",
            "-                            break;",
            "-                        }",
            "                     }",
            "                 }",
            "                 // End of partition batch iteration.",
            "             }",
            "             // End of pass iteration.",
            "         }",
            " ",
            "         Ok(())",
            "     }",
            " ",
            "-    /// Ensures there is enough storage for `len` partition classes.",
            "+    /// Ensures enough storage for `len` partition classes.",
            "     #[inline]",
            "-    fn setup_part_classes(&mut self, len: usize) {",
            "+    fn prepare_partition_classes(&mut self, len: usize) {",
            "         if self.part_classes.len() < len {",
            "             self.part_classes.resize(len, Default::default());",
            "         }",
            "     }",
            " ",
            "     /// Ensures the interleave buffer for type 2 residues can accomodate `len` samples, and that the",
            "-    /// samples are zeroed.",
            "+    /// buffer is zeroed.",
            "     #[inline]",
            "-    fn setup_type2_buf(&mut self, len: usize) {",
            "+    fn prepare_type_2_format_buffer(&mut self, len: usize) {",
            "         if self.type2_buf.len() < len {",
            "             self.type2_buf.resize(len, Default::default());",
            "         }",
            "         self.type2_buf[..len].fill(0.0);",
            "     }",
            " }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-core/src/io/bit.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-core/src/io/bit.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-core/src/io/bit.rs",
            "@@ -217,14 +217,16 @@",
            "     );",
            " ",
            "     /// `Codebook` is a variable-length code decoding table that may be used to efficiently read",
            "     /// symbols from a source of bits.",
            "     #[derive(Default)]",
            "     pub struct Codebook<E: CodebookEntry> {",
            "         pub table: Vec<E>,",
            "+        pub max_code_len: u32,",
            "+        pub init_block_len: u32,",
            "     }",
            " ",
            "     impl<E: CodebookEntry> Codebook<E> {",
            "         /// Returns `true` if the `Codebook` is empty.",
            "         pub fn is_empty(&self) -> bool {",
            "             self.table.is_empty()",
            "         }",
            "@@ -434,14 +436,16 @@",
            "             values: &[E::ValueType],",
            "         ) -> io::Result<Codebook<E>> {",
            "             assert!(code_words.len() == code_lens.len());",
            "             assert!(code_words.len() == values.len());",
            " ",
            "             let mut blocks = Vec::<CodebookBlock<E>>::new();",
            " ",
            "+            let mut max_code_len = 0;",
            "+",
            "             // Only attempt to generate something if there are code words.",
            "             if !code_words.is_empty() {",
            "                 let prefix_mask = !(!0 << self.max_bits_per_block);",
            " ",
            "                 // Push a root block.",
            "                 blocks.push(Default::default());",
            " ",
            "@@ -470,15 +474,15 @@",
            "                         if let Some(&block_id) = blocks[parent_block_id].nodes.get(&prefix) {",
            "                             parent_block_id = block_id;",
            "                         }",
            "                         else {",
            "                             // Add a child block to the parent block.",
            "                             let block_id = blocks.len();",
            " ",
            "-                            let mut block = &mut blocks[parent_block_id];",
            "+                            let block = &mut blocks[parent_block_id];",
            " ",
            "                             block.nodes.insert(prefix, block_id);",
            " ",
            "                             // The parent's block width must accomodate the prefix of the child.",
            "                             // This is always max_bits_per_block bits.",
            "                             block.width = self.max_bits_per_block;",
            " ",
            "@@ -489,28 +493,34 @@",
            "                         }",
            "                     }",
            " ",
            "                     // The final chunk of code bits always has <= max_bits_per_block bits. Obtain",
            "                     // the final prefix.",
            "                     let prefix = code & (prefix_mask >> (self.max_bits_per_block - len));",
            " ",
            "-                    let mut block = &mut blocks[parent_block_id];",
            "+                    let block = &mut blocks[parent_block_id];",
            " ",
            "                     // Push the value.",
            "                     block.values.push(CodebookValue::new(prefix as u16, len, value));",
            " ",
            "                     // Update the block's width.",
            "                     block.width = max(block.width, len);",
            "+",
            "+                    // Update maximum observed codeword.",
            "+                    max_code_len = max(max_code_len, code_len);",
            "                 }",
            "             }",
            " ",
            "-            // Generate Codebook's lookup table.",
            "+            // Generate the codebook lookup table.",
            "             let table = CodebookBuilder::generate_lut(self.bit_order, self.is_sparse, &blocks)?;",
            " ",
            "-            Ok(Codebook { table })",
            "+            // Determine the first block length if skipping the initial jump entry.",
            "+            let init_block_len = table.first().map(|block| block.jump_len()).unwrap_or(0);",
            "+",
            "+            Ok(Codebook { table, max_code_len: u32::from(max_code_len), init_block_len })",
            "         }",
            "     }",
            " }",
            " ",
            " mod private {",
            "     use std::io;",
            " ",
            "@@ -825,61 +835,59 @@",
            "     /// Reads a codebook value from the `BitStream` using the provided `Codebook` and returns the",
            "     /// decoded value or an error.",
            "     #[inline(always)]",
            "     fn read_codebook<E: vlc::CodebookEntry>(",
            "         &mut self,",
            "         codebook: &vlc::Codebook<E>,",
            "     ) -> io::Result<(E::ValueType, u32)> {",
            "-        debug_assert!(!codebook.is_empty());",
            "+        // Attempt refill the bit buffer with enough bits for the longest codeword in the codebook.",
            "+        // However, this does not mean the bit buffer will have enough bits to decode a codeword.",
            "+        if self.num_bits_left() < codebook.max_code_len {",
            "+            self.fetch_bits_partial()?;",
            "+        }",
            " ",
            "-        let mut code_len = 0;",
            "-        let mut jmp_read_len = 0;",
            "+        // The number of bits actually buffered in the bit buffer.",
            "+        let num_bits_left = self.num_bits_left();",
            " ",
            "-        let mut entry = codebook.table[0];",
            "+        let mut bits = self.get_bits();",
            " ",
            "-        while entry.is_jump() {",
            "-            // Consume bits from the last jump.",
            "-            self.consume_bits(jmp_read_len);",
            "+        let mut block_len = codebook.init_block_len;",
            "+        let mut entry = codebook.table[(bits >> (u64::BITS - block_len)) as usize + 1];",
            " ",
            "-            // Update decoded code length.",
            "-            code_len += jmp_read_len;",
            "+        let mut consumed = 0;",
            " ",
            "-            // The length of the next run of bits to read.",
            "-            jmp_read_len = entry.jump_len();",
            "+        while entry.is_jump() {",
            "+            // Consume the bits used for the initial or previous jump iteration.",
            "+            consumed += block_len;",
            "+            bits <<= block_len;",
            " ",
            "-            let addr = self.get_bits() >> (u64::BITS - jmp_read_len);",
            "+            // Since this is a jump entry, if there are no bits left then the bitstream ended early.",
            "+            if consumed > num_bits_left {",
            "+                return end_of_bitstream_error();",
            "+            }",
            " ",
            "-            // Jump!",
            "-            let jmp_offset = entry.jump_offset();",
            "+            // Prepare for the next jump.",
            "+            block_len = entry.jump_len();",
            " ",
            "-            entry = codebook.table[jmp_offset + addr as usize];",
            "+            let index = bits >> (u64::BITS - block_len);",
            " ",
            "-            // The bit cache cannot fully service next lookup. Try to use the remaining bits (addr)",
            "-            // as a prefix. If it points to a value entry that has a code length that's <= the",
            "-            // remaining number of bits, then no further reads are necessary.",
            "-            if self.num_bits_left() < jmp_read_len {",
            "-                if entry.is_value() && entry.value_len() <= self.num_bits_left() {",
            "-                    break;",
            "-                }",
            "-",
            "-                // Fetch more bits without discarding the unconsumed bits.",
            "-                self.fetch_bits_partial()?;",
            "+            // Jump to the next entry.",
            "+            entry = codebook.table[entry.jump_offset() + index as usize];",
            "+        }",
            " ",
            "-                let addr = self.get_bits() >> (u64::BITS - jmp_read_len);",
            "+        // The entry is always a value entry at this point. Consume the bits containing the value.",
            "+        consumed += entry.value_len();",
            " ",
            "-                entry = codebook.table[jmp_offset + addr as usize];",
            "-            }",
            "+        if consumed > num_bits_left {",
            "+            return end_of_bitstream_error();",
            "         }",
            " ",
            "-        // Consume the bits from the value entry.",
            "-        let entry_code_len = entry.value_len();",
            "-",
            "-        self.consume_bits(entry_code_len);",
            "+        self.consume_bits(consumed);",
            " ",
            "-        Ok((entry.value(), code_len + entry_code_len))",
            "+        Ok((entry.value(), consumed))",
            "     }",
            " }",
            " ",
            " /// `BitStreamLtr` reads bits from most-significant to least-significant from any source",
            " /// that implements [`ReadBytes`].",
            " ///",
            " /// Stated another way, if N-bits are read from a `BitReaderLtr` then bit 0, the first bit read,",
            "@@ -903,16 +911,14 @@",
            "         self.bits = u64::from(self.reader.read_u8()?) << 56;",
            "         self.n_bits_left = u8::BITS;",
            "         Ok(())",
            "     }",
            " ",
            "     #[inline(always)]",
            "     fn fetch_bits_partial(&mut self) -> io::Result<()> {",
            "-        self.bits |= u64::from(self.reader.read_u8()?) << (u64::BITS - self.n_bits_left);",
            "-        self.n_bits_left += u8::BITS;",
            "         todo!()",
            "     }",
            " ",
            "     #[inline(always)]",
            "     fn get_bits(&self) -> u64 {",
            "         self.bits",
            "     }",
            "@@ -945,23 +951,20 @@",
            "     /// Instantiate a new `BitReaderLtr` with the given buffer.",
            "     pub fn new(buf: &'a [u8]) -> Self {",
            "         BitReaderLtr { buf, bits: 0, n_bits_left: 0 }",
            "     }",
            " }",
            " ",
            " impl<'a> private::FetchBitsLtr for BitReaderLtr<'a> {",
            "+    #[inline]",
            "     fn fetch_bits_partial(&mut self) -> io::Result<()> {",
            "         let mut buf = [0u8; std::mem::size_of::<u64>()];",
            " ",
            "         let read_len = min(self.buf.len(), (u64::BITS - self.n_bits_left) as usize >> 3);",
            " ",
            "-        if read_len == 0 {",
            "-            return end_of_bitstream_error();",
            "-        }",
            "-",
            "         buf[..read_len].copy_from_slice(&self.buf[..read_len]);",
            " ",
            "         self.buf = &self.buf[read_len..];",
            " ",
            "         self.bits |= u64::from_be_bytes(buf) >> self.n_bits_left;",
            "         self.n_bits_left += (read_len as u32) << 3;",
            " ",
            "@@ -1278,68 +1281,62 @@",
            " ",
            "             self.fetch_bits()?;",
            "         }",
            " ",
            "         Ok(num)",
            "     }",
            " ",
            "-    /// Reads a codebook value from the `BitStream` using the provided `Codebook` and returns the",
            "-    /// decoded value or an error.",
            "     #[inline(always)]",
            "     fn read_codebook<E: vlc::CodebookEntry>(",
            "         &mut self,",
            "         codebook: &vlc::Codebook<E>,",
            "     ) -> io::Result<(E::ValueType, u32)> {",
            "-        debug_assert!(!codebook.is_empty());",
            "-",
            "-        let mut code_len = 0;",
            "-        let mut jmp_read_len = 0;",
            "+        if self.num_bits_left() < codebook.max_code_len {",
            "+            self.fetch_bits_partial()?;",
            "+        }",
            " ",
            "-        let mut entry = codebook.table[0];",
            "+        // The number of bits actually buffered in the bit buffer.",
            "+        let num_bits_left = self.num_bits_left();",
            " ",
            "-        while entry.is_jump() {",
            "-            // Consume bits from the last jump.",
            "-            self.consume_bits(jmp_read_len);",
            "+        let mut bits = self.get_bits();",
            " ",
            "-            // Update decoded code length.",
            "-            code_len += jmp_read_len;",
            "+        let mut block_len = codebook.init_block_len;",
            "+        let mut entry = codebook.table[(bits & ((1 << block_len) - 1)) as usize + 1];",
            " ",
            "-            // The length of the next run of bits to read.",
            "-            jmp_read_len = entry.jump_len();",
            "+        let mut consumed = 0;",
            " ",
            "-            let addr = self.get_bits() & ((1 << jmp_read_len) - 1);",
            "+        while entry.is_jump() {",
            "+            // Consume the bits used for the initial or previous jump iteration.",
            "+            consumed += block_len;",
            "+            bits >>= block_len;",
            " ",
            "-            // Jump!",
            "-            let jmp_offset = entry.jump_offset();",
            "+            // Since this is a jump entry, if there are no bits left then the bitstream ended early.",
            "+            if consumed > num_bits_left {",
            "+                return end_of_bitstream_error();",
            "+            }",
            " ",
            "-            entry = codebook.table[jmp_offset + addr as usize];",
            "+            // Prepare for the next jump.",
            "+            block_len = entry.jump_len();",
            " ",
            "-            // The bit cache cannot fully service next lookup. Try to use the remaining bits (addr)",
            "-            // as a prefix. If it points to a value entry that has a code length that's <= the",
            "-            // remaining number of bits, then no further reads are necessary.",
            "-            if self.num_bits_left() < jmp_read_len {",
            "-                if entry.is_value() && entry.value_len() <= self.num_bits_left() {",
            "-                    break;",
            "-                }",
            "+            let index = bits & ((1 << block_len) - 1);",
            " ",
            "-                // Fetch more bits without discarding the unconsumed bits.",
            "-                self.fetch_bits_partial()?;",
            "+            // Jump to the next entry.",
            "+            entry = codebook.table[entry.jump_offset() + index as usize];",
            "+        }",
            " ",
            "-                let addr = self.get_bits() & ((1 << jmp_read_len) - 1);",
            "+        // The entry is always a value entry at this point. Consume the bits containing the value.",
            "+        consumed += entry.value_len();",
            " ",
            "-                entry = codebook.table[jmp_offset + addr as usize];",
            "-            }",
            "+        if consumed > num_bits_left {",
            "+            return end_of_bitstream_error();",
            "         }",
            " ",
            "-        // Consume the bits from the value entry.",
            "-        let entry_code_len = entry.value_len();",
            "-",
            "-        self.consume_bits(entry_code_len);",
            "+        self.consume_bits(consumed);",
            " ",
            "-        Ok((entry.value(), code_len + entry_code_len))",
            "+        Ok((entry.value(), consumed))",
            "     }",
            " }",
            " ",
            " /// `BitStreamRtl` reads bits from least-significant to most-significant from any source",
            " /// that implements [`ReadBytes`].",
            " ///",
            " /// Stated another way, if N-bits are read from a `BitReaderLtr` then bit 0, the first bit read,",
            "@@ -1363,16 +1360,14 @@",
            "         self.bits = u64::from(self.reader.read_u8()?);",
            "         self.n_bits_left = u8::BITS;",
            "         Ok(())",
            "     }",
            " ",
            "     #[inline(always)]",
            "     fn fetch_bits_partial(&mut self) -> io::Result<()> {",
            "-        self.bits |= u64::from(self.reader.read_u8()?) << self.n_bits_left;",
            "-        self.n_bits_left += u8::BITS;",
            "         todo!()",
            "     }",
            " ",
            "     #[inline(always)]",
            "     fn get_bits(&self) -> u64 {",
            "         self.bits",
            "     }",
            "@@ -1405,23 +1400,20 @@",
            "     /// Instantiate a new `BitReaderRtl` with the given buffer.",
            "     pub fn new(buf: &'a [u8]) -> Self {",
            "         BitReaderRtl { buf, bits: 0, n_bits_left: 0 }",
            "     }",
            " }",
            " ",
            " impl<'a> private::FetchBitsRtl for BitReaderRtl<'a> {",
            "+    #[inline]",
            "     fn fetch_bits_partial(&mut self) -> io::Result<()> {",
            "         let mut buf = [0u8; std::mem::size_of::<u64>()];",
            " ",
            "         let read_len = min(self.buf.len(), (u64::BITS - self.n_bits_left) as usize >> 3);",
            " ",
            "-        if read_len == 0 {",
            "-            return end_of_bitstream_error();",
            "-        }",
            "-",
            "         buf[..read_len].copy_from_slice(&self.buf[..read_len]);",
            " ",
            "         self.buf = &self.buf[read_len..];",
            " ",
            "         self.bits |= u64::from_le_bytes(buf) << self.n_bits_left;",
            "         self.n_bits_left += (read_len as u32) << 3;"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-core/src/meta.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-core/src/meta.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-core/src/meta.rs",
            "@@ -65,15 +65,15 @@",
            " ",
            " /// `StandardVisualKey` is an enumeration providing standardized keys for common visual dispositions.",
            " /// A demuxer may assign a `StandardVisualKey` to a `Visual` if the disposition of the attached",
            " /// visual is known and can be mapped to a standard key.",
            " ///",
            " /// The visual types listed here are derived from, though do not entirely cover, the ID3v2 APIC",
            " /// frame specification.",
            "-#[derive(Copy, Clone, Debug, PartialEq, Eq)]",
            "+#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]",
            " pub enum StandardVisualKey {",
            "     FileIcon,",
            "     OtherIcon,",
            "     FrontCover,",
            "     BackCover,",
            "     Leaflet,",
            "     Media,",
            "@@ -91,15 +91,15 @@",
            "     BandArtistLogo,",
            "     PublisherStudioLogo,",
            " }",
            " ",
            " /// `StandardTagKey` is an enumeration providing standardized keys for common tag types.",
            " /// A tag reader may assign a `StandardTagKey` to a `Tag` if the tag's key is generally",
            " /// accepted to map to a specific usage.",
            "-#[derive(Copy, Clone, Debug, PartialEq, Eq)]",
            "+#[derive(Copy, Clone, Debug, PartialEq, Eq, Hash)]",
            " pub enum StandardTagKey {",
            "     AcoustidFingerprint,",
            "     AcoustidId,",
            "     Album,",
            "     AlbumArtist,",
            "     Arranger,",
            "     Artist,",
            "@@ -394,14 +394,17 @@",
            "     tags: Vec<Tag>,",
            "     visuals: Vec<Visual>,",
            "     vendor_data: Vec<VendorData>,",
            " }",
            " ",
            " impl MetadataRevision {",
            "     /// Gets an immutable slice to the `Tag`s in this revision.",
            "+    ///",
            "+    /// If a tag read from the source contained multiple values, then there will be one `Tag` item",
            "+    /// per value, with each item having the same key and standard key.",
            "     pub fn tags(&self) -> &[Tag] {",
            "         &self.tags",
            "     }",
            " ",
            "     /// Gets an immutable slice to the `Visual`s in this revision.",
            "     pub fn visuals(&self) -> &[Visual] {",
            "         &self.visuals",
            "@@ -462,15 +465,16 @@",
            "     }",
            " ",
            "     /// Gets an immutable reference to the current, and therefore oldest, revision of the metadata.",
            "     pub fn current(&self) -> Option<&MetadataRevision> {",
            "         self.revisions.front()",
            "     }",
            " ",
            "-    /// Skips to, and gets an immutable reference to the latest, and therefore newest, revision of the metadata.",
            "+    /// Skips to, and gets an immutable reference to the latest, and therefore newest, revision of",
            "+    /// the metadata.",
            "     pub fn skip_to_latest(&mut self) -> Option<&MetadataRevision> {",
            "         loop {",
            "             if self.pop().is_none() {",
            "                 break;",
            "             }",
            "         }",
            "         self.current()"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-core/src/probe.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-core/src/probe.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-core/src/probe.rs",
            "@@ -233,14 +233,18 @@",
            " ",
            "         // Scan the stream byte-by-byte. Shifting each byte through a 2-byte window.",
            "         while let Ok(byte) = mss.read_byte() {",
            "             win = (win << 8) | u16::from(byte);",
            " ",
            "             count += 1;",
            " ",
            "+            if count > Probe::PROBE_SEARCH_LIMIT {",
            "+                break;",
            "+            }",
            "+",
            "             if count % 4096 == 0 {",
            "                 debug!(",
            "                     \"searching for format marker... {}+{} / {} bytes.\",",
            "                     init_pos,",
            "                     count,",
            "                     Probe::PROBE_SEARCH_LIMIT",
            "                 );",
            "@@ -287,16 +291,21 @@",
            "                 // If no registered markers were matched, then the bloom filter returned a false",
            "                 // positive. Re-align the stream to the end of the 2-byte window and continue the",
            "                 // search.",
            "                 mss.seek_buffered_rev(16 - 2);",
            "             }",
            "         }",
            " ",
            "-        // Could not find any marker within the probe limit.",
            "-        error!(\"reached probe limit of {} bytes.\", Probe::PROBE_SEARCH_LIMIT);",
            "+        if count < Probe::PROBE_SEARCH_LIMIT {",
            "+            error!(\"probe reach EOF at {} bytes.\", count);",
            "+        }",
            "+        else {",
            "+            // Could not find any marker within the probe limit.",
            "+            error!(\"reached probe limit of {} bytes.\", Probe::PROBE_SEARCH_LIMIT);",
            "+        }",
            " ",
            "         unsupported_error(\"core (probe): no suitable format reader found\")",
            "     }",
            " ",
            "     /// Searches the provided `MediaSourceStream` for a container format. Any metadata that is read",
            "     /// during the search will be queued and attached to the `FormatReader` instance once a",
            "     /// container format is found."
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-core/src/sample.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-core/src/sample.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-core/src/sample.rs",
            "@@ -26,15 +26,15 @@",
            "     S8,",
            "     /// Signed 16-bit integer.",
            "     S16,",
            "     /// Signed 24-bit integer.",
            "     S24,",
            "     /// Signed 32-bit integer.",
            "     S32,",
            "-    /// Single prevision (32-bit) floating point.",
            "+    /// Single precision (32-bit) floating point.",
            "     F32,",
            "     /// Double precision (64-bit) floating point.",
            "     F64,",
            " }",
            " ",
            " /// `Sample` provides a common interface for manipulating sample's regardless of the",
            " /// underlying data type. Additionally, `Sample` provides information regarding the"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-core/src/units.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-core/src/units.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-core/src/units.rs",
            "@@ -114,14 +114,26 @@",
            "         }",
            "         else {",
            "             Time::new(0, 0.0)",
            "         }",
            "     }",
            " }",
            " ",
            "+impl From<std::time::Duration> for Time {",
            "+    fn from(duration: std::time::Duration) -> Self {",
            "+        Time::new(duration.as_secs(), f64::from(duration.subsec_nanos()) / 1_000_000_000.0)",
            "+    }",
            "+}",
            "+",
            "+impl From<Time> for std::time::Duration {",
            "+    fn from(time: Time) -> Self {",
            "+        std::time::Duration::new(time.seconds, (1_000_000_000.0 * time.frac) as u32)",
            "+    }",
            "+}",
            "+",
            " /// A `TimeBase` is the conversion factor between time, expressed in seconds, and a `TimeStamp` or",
            " /// `Duration`.",
            " ///",
            " /// In other words, a `TimeBase` is the length in seconds of one tick of a `TimeStamp` or",
            " /// `Duration`.",
            " #[derive(Copy, Clone, Debug, Default, PartialEq, Eq, PartialOrd, Ord)]",
            " pub struct TimeBase {",
            "@@ -227,14 +239,15 @@",
            "         write!(f, \"{}/{}\", self.numer, self.denom)",
            "     }",
            " }",
            " ",
            " #[cfg(test)]",
            " mod tests {",
            "     use super::{Time, TimeBase};",
            "+    use std::time::Duration;",
            " ",
            "     #[test]",
            "     fn verify_timebase() {",
            "         // Verify accuracy of timestamp -> time",
            "         let tb1 = TimeBase::new(1, 320);",
            " ",
            "         assert_eq!(tb1.calc_time(0), Time::new(0, 0.0));",
            "@@ -256,8 +269,30 @@",
            "         );",
            "         assert_eq!(",
            "             tb1.calc_timestamp(Time::new(14_073_748_835_532, 0.803125)),",
            "             0x10_0000_0000_0001",
            "         );",
            "         assert_eq!(tb1.calc_timestamp(Time::new(57_646_075_230_342_348, 0.796875)), u64::MAX);",
            "     }",
            "+",
            "+    #[test]",
            "+    fn verify_duration_to_time() {",
            "+        // Verify accuracy of Duration -> Time",
            "+        let dur1 = Duration::from_secs_f64(38.578125);",
            "+        let time1 = Time::from(dur1);",
            "+",
            "+        assert_eq!(time1.seconds, 38);",
            "+        assert_eq!(time1.frac, 0.578125);",
            "+    }",
            "+",
            "+    #[test]",
            "+    fn verify_time_to_duration() {",
            "+        // Verify accuracy of Time -> Duration",
            "+        let time1 = Time::new(38, 0.578125);",
            "+        let dur1 = Duration::from(time1);",
            "+",
            "+        let seconds = dur1.as_secs_f64();",
            "+",
            "+        assert_eq!(seconds.trunc(), 38.0);",
            "+        assert_eq!(seconds.fract(), 0.578125);",
            "+    }",
            " }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-isomp4/src/atoms/mod.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-isomp4/src/atoms/mod.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-isomp4/src/atoms/mod.rs",
            "@@ -46,14 +46,15 @@",
            " pub(crate) mod trun;",
            " pub(crate) mod udta;",
            " pub(crate) mod wave;",
            " ",
            " pub use self::meta::MetaAtom;",
            " pub use alac::AlacAtom;",
            " pub use co64::Co64Atom;",
            "+#[allow(unused_imports)]",
            " pub use ctts::CttsAtom;",
            " pub use edts::EdtsAtom;",
            " pub use elst::ElstAtom;",
            " pub use esds::EsdsAtom;",
            " pub use flac::FlacAtom;",
            " pub use ftyp::FtypAtom;",
            " pub use hdlr::HdlrAtom;",
            "@@ -70,14 +71,15 @@",
            " pub use opus::OpusAtom;",
            " pub use sidx::SidxAtom;",
            " pub use smhd::SmhdAtom;",
            " pub use stbl::StblAtom;",
            " pub use stco::StcoAtom;",
            " pub use stsc::StscAtom;",
            " pub use stsd::StsdAtom;",
            "+#[allow(unused_imports)]",
            " pub use stss::StssAtom;",
            " pub use stsz::StszAtom;",
            " pub use stts::SttsAtom;",
            " pub use tfhd::TfhdAtom;",
            " pub use tkhd::TkhdAtom;",
            " pub use traf::TrafAtom;",
            " pub use trak::TrakAtom;",
            "@@ -431,22 +433,23 @@",
            "             }",
            "         }",
            " ",
            "         // Read the next atom header.",
            "         let atom = AtomHeader::read(&mut self.reader)?;",
            " ",
            "         // Calculate the start position for the next atom (the exclusive end of the current atom).",
            "-        self.next_atom_pos += match atom.atom_len {",
            "+        self.next_atom_pos = match atom.atom_len {",
            "             0 => {",
            "                 // An atom with a length of zero is defined to span to the end of the stream. If",
            "                 // len is available, use it for the next atom start position, otherwise, use u64 max",
            "                 // which will trip an end of stream error on the next iteration.",
            "-                self.len.unwrap_or(std::u64::MAX) - self.next_atom_pos",
            "+                self.len.map(|l| self.base_pos + l).unwrap_or(std::u64::MAX)",
            "             }",
            "-            len => len,",
            "+",
            "+            len => self.next_atom_pos + len,",
            "         };",
            " ",
            "         self.cur_atom = Some(atom);",
            " ",
            "         Ok(self.cur_atom)",
            "     }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-mkv/src/demuxer.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-mkv/src/demuxer.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-mkv/src/demuxer.rs",
            "@@ -195,15 +195,15 @@",
            "         }",
            "     }",
            " ",
            "     fn next_element(&mut self) -> Result<()> {",
            "         if let Some(ClusterState { end: Some(end), .. }) = &self.current_cluster {",
            "             // Make sure we don't read past the current cluster if its size is known.",
            "             if self.iter.pos() >= *end {",
            "-                log::debug!(\"ended cluster\");",
            "+                // log::debug!(\"ended cluster\");",
            "                 self.current_cluster = None;",
            "             }",
            "         }",
            " ",
            "         // Each Cluster is being read incrementally so we need to keep track of",
            "         // which cluster we are currently in.",
            " ",
            "@@ -386,14 +386,18 @@",
            " ",
            "         if is_seekable {",
            "             // Make sure we don't jump backwards unnecessarily.",
            "             seek_positions.sort_by_key(|sp| sp.1);",
            " ",
            "             for (etype, pos) in seek_positions {",
            "                 it.seek(pos)?;",
            "+",
            "+                // Safety: The element type or position may be incorrect. The element iterator will",
            "+                // validate the type (as declared in the header) of the element at the seeked",
            "+                // position against the element type asked to be read.",
            "                 match etype {",
            "                     ElementType::Tracks => {",
            "                         segment_tracks = Some(it.read_element::<TracksElement>()?);",
            "                     }",
            "                     ElementType::Info => {",
            "                         info = Some(it.read_element::<InfoElement>()?);",
            "                     }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-mkv/src/ebml.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-mkv/src/ebml.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-mkv/src/ebml.rs",
            "@@ -32,15 +32,15 @@",
            "         // Read remaining octets",
            "         let mut vint = u32::from(byte);",
            "         for _ in 0..remaining_octets {",
            "             let byte = reader.read_byte()?;",
            "             vint = (vint << 8) | u32::from(byte);",
            "         }",
            " ",
            "-        log::debug!(\"element with tag: {:X}\", vint);",
            "+        // log::debug!(\"element with tag: {:X}\", vint);",
            "         return Ok((vint, remaining_octets + 1, false));",
            "     }",
            " ",
            "     // Seek to next supported tag of a top level element (`Cluster`, `Info`, etc.)",
            "     let mut tag = 0u32;",
            "     loop {",
            "         let ty = ELEMENTS.get(&tag).map(|(_, ty)| ty).filter(|ty| ty.is_top_level());",
            "@@ -337,19 +337,19 @@",
            "         self.read_element_data()",
            "     }",
            " ",
            "     /// Reads data of current element. Must be used after",
            "     /// [Self::read_header] or [Self::read_child_header].",
            "     pub(crate) fn read_element_data<E: Element>(&mut self) -> Result<E> {",
            "         let header = self.current.expect(\"EBML header must be read before calling this function\");",
            "-        assert_eq!(",
            "-            header.etype,",
            "-            E::ID,",
            "-            \"EBML element type must be checked before calling this function\"",
            "-        );",
            "+",
            "+        // Ensure the EBML element header has the same element type as the one being read.",
            "+        if header.etype != E::ID {",
            "+            return decode_error(\"mkv: unexpected EBML element\");",
            "+        }",
            " ",
            "         let element = E::read(&mut self.reader, header)?;",
            "         // Update position to match the position element reader finished at",
            "         self.next_pos = self.reader.pos();",
            "         Ok(element)",
            "     }"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-ogg/src/demuxer.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-ogg/src/demuxer.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-ogg/src/demuxer.rs",
            "@@ -114,71 +114,78 @@",
            " ",
            "     fn do_seek(&mut self, serial: u32, required_ts: u64) -> Result<SeekedTo> {",
            "         // If the reader is seekable, then use the bisection method to coarsely seek to the nearest",
            "         // page that ends before the required timestamp.",
            "         if self.reader.is_seekable() {",
            "             let stream = self.streams.get_mut(&serial).unwrap();",
            " ",
            "-            // The end of the physical stream.",
            "-            let physical_end = self.phys_byte_range_end.unwrap();",
            "-",
            "+            // Bisection method byte ranges. When these two values are equal, the bisection has",
            "+            // converged on the position of the correct page.",
            "             let mut start_byte_pos = self.phys_byte_range_start;",
            "-            let mut end_byte_pos = physical_end;",
            "+            let mut end_byte_pos = self.phys_byte_range_end.unwrap();",
            " ",
            "-            // Bisection method.",
            "-            loop {",
            "+            // Bisect the stream while the byte range is large. For smaller ranges, a linear scan is",
            "+            // faster than having the the binary search converge.",
            "+            while end_byte_pos - start_byte_pos > 2 * OGG_PAGE_MAX_SIZE as u64 {",
            "                 // Find the middle of the upper and lower byte search range.",
            "                 let mid_byte_pos = (start_byte_pos + end_byte_pos) / 2;",
            " ",
            "                 // Seek to the middle of the byte range.",
            "                 self.reader.seek(SeekFrom::Start(mid_byte_pos))?;",
            " ",
            "                 // Read the next page.",
            "                 match self.pages.next_page_for_serial(&mut self.reader, serial) {",
            "                     Ok(_) => (),",
            "-                    _ => return seek_error(SeekErrorKind::OutOfRange),",
            "+                    _ => {",
            "+                        // No more pages for the stream from the mid-point onwards.",
            "+                        debug!(",
            "+                            \"seek: bisect step: byte_range=[{}, {}, {}]\",",
            "+                            start_byte_pos, mid_byte_pos, end_byte_pos,",
            "+                        );",
            "+",
            "+                        end_byte_pos = mid_byte_pos;",
            "+                        continue;",
            "+                    }",
            "                 }",
            " ",
            "                 // Probe the page to get the start and end timestamp.",
            "                 let (start_ts, end_ts) = stream.inspect_page(&self.pages.page());",
            " ",
            "                 debug!(",
            "-                    \"seek: bisect step: page={{ start={}, end={} }} byte_range=[{}..{}], mid={}\",",
            "-                    start_ts, end_ts, start_byte_pos, end_byte_pos, mid_byte_pos,",
            "+                    \"seek: bisect step: page={{ start_ts={}, end_ts={} }} byte_range=[{}, {}, {}]\",",
            "+                    start_ts, end_ts, start_byte_pos, mid_byte_pos, end_byte_pos,",
            "                 );",
            " ",
            "                 if required_ts < start_ts {",
            "-                    // The required timestamp is less-than the timestamp of the first sample in",
            "-                    // page1. Update the upper bound and bisect again.",
            "+                    // The required timestamp is less-than the timestamp of the first sample in the",
            "+                    // page. Update the upper bound and bisect again.",
            "                     end_byte_pos = mid_byte_pos;",
            "                 }",
            "                 else if required_ts > end_ts {",
            "                     // The required timestamp is greater-than the timestamp of the final sample in",
            "-                    // the in page1. Update the lower bound and bisect again.",
            "+                    // the in the page. Update the lower bound and bisect again.",
            "                     start_byte_pos = mid_byte_pos;",
            "                 }",
            "                 else {",
            "-                    // The sample with the required timestamp is contained in page1. Return the",
            "-                    // byte position for page0, and the timestamp of the first sample in page1, so",
            "-                    // that when packets from page1 are read, those packets will have a non-zero",
            "-                    // base timestamp.",
            "+                    // The sample with the required timestamp is contained in the page. The",
            "+                    // bisection has converged on the correct page so stop the bisection.",
            "+                    start_byte_pos = mid_byte_pos;",
            "+                    end_byte_pos = mid_byte_pos;",
            "                     break;",
            "                 }",
            "+            }",
            " ",
            "-                // Prevent infinite iteration and too many seeks when the search range is less",
            "-                // than 2x the maximum page size.",
            "-                if end_byte_pos - start_byte_pos <= 2 * OGG_PAGE_MAX_SIZE as u64 {",
            "-                    self.reader.seek(SeekFrom::Start(start_byte_pos))?;",
            "-",
            "-                    match self.pages.next_page_for_serial(&mut self.reader, serial) {",
            "-                        Ok(_) => (),",
            "-                        _ => return seek_error(SeekErrorKind::OutOfRange),",
            "-                    }",
            "+            // If the bisection did not converge, then the linear search must continue from the",
            "+            // lower-bound (start) position of what would've been the next iteration of bisection.",
            "+            if start_byte_pos != end_byte_pos {",
            "+                self.reader.seek(SeekFrom::Start(start_byte_pos))?;",
            " ",
            "-                    break;",
            "+                match self.pages.next_page_for_serial(&mut self.reader, serial) {",
            "+                    Ok(_) => (),",
            "+                    _ => return seek_error(SeekErrorKind::OutOfRange),",
            "                 }",
            "             }",
            " ",
            "             // Reset all logical bitstreams since the physical stream will be reading from a new",
            "             // location now.",
            "             for (&s, stream) in self.streams.iter_mut() {",
            "                 stream.reset();"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-ogg/src/logical.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-ogg/src/logical.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-ogg/src/logical.rs",
            "@@ -47,15 +47,15 @@",
            "     prev_page_info: Option<PageInfo>,",
            "     start_bound: Option<Bound>,",
            "     end_bound: Option<Bound>,",
            "     gapless: bool,",
            " }",
            " ",
            " impl LogicalStream {",
            "-    const MAX_PACKET_LEN: usize = 8 * 1024 * 1024;",
            "+    const MAX_PACKET_LEN: usize = 16 * 1024 * 1024;",
            " ",
            "     pub fn new(mapper: Box<dyn Mapper>, gapless: bool) -> Self {",
            "         LogicalStream {",
            "             mapper,",
            "             packets: Default::default(),",
            "             part_buf: Default::default(),",
            "             part_len: 0,"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-ogg/src/mappings/opus.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-ogg/src/mappings/opus.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-ogg/src/mappings/opus.rs",
            "@@ -146,17 +146,71 @@",
            " ",
            "     Ok(Some(mapper))",
            " }",
            " ",
            " pub struct OpusPacketParser {}",
            " ",
            " impl PacketParser for OpusPacketParser {",
            "-    fn parse_next_packet_dur(&mut self, _packet: &[u8]) -> u64 {",
            "-        // TODO: Implement.",
            "-        0",
            "+    fn parse_next_packet_dur(&mut self, packet: &[u8]) -> u64 {",
            "+        // See https://www.rfc-editor.org/rfc/rfc6716",
            "+        // Read TOC (Table Of Contents) byte which is the first byte in the opus data.",
            "+        let toc_byte = match packet.first() {",
            "+            Some(b) => b,",
            "+            None => {",
            "+                warn!(\"opus packet empty\");",
            "+                return 0;",
            "+            }",
            "+        };",
            "+        // The configuration number is the 5 most significant bits. Shift out 3 least significant",
            "+        // bits.",
            "+        let configuration_number = toc_byte >> 3; // max 2^5-1 = 31",
            "+",
            "+        // The configuration number maps to packet length according to this lookup table.",
            "+        // See https://www.rfc-editor.org/rfc/rfc6716 top half of page 14.",
            "+        // Numbers are in milliseconds in the rfc. Down below they are in TimeBase units, so",
            "+        // 10ms = 10*48.",
            "+        #[rustfmt::skip]",
            "+        const CONFIGURATION_NUMBER_TO_FRAME_DURATION: [u32; 32] = [",
            "+            10*48, 20*48, 40*48, 60*48,",
            "+            10*48, 20*48, 40*48, 60*48,",
            "+            10*48, 20*48, 40*48, 60*48,",
            "+            10*48, 20*48,",
            "+            10*48, 20*48,",
            "+            (2.5*48.0) as u32, 5*48, 10*48, 20*48,",
            "+            (2.5*48.0) as u32, 5*48, 10*48, 20*48,",
            "+            (2.5*48.0) as u32, 5*48, 10*48, 20*48,",
            "+            (2.5*48.0) as u32, 5*48, 10*48, 20*48,",
            "+        ];",
            "+        // Look up the frame length.",
            "+        let frame_duration =",
            "+            CONFIGURATION_NUMBER_TO_FRAME_DURATION[configuration_number as usize] as u64;",
            "+",
            "+        // Look up the number of frames in the packet.",
            "+        // See https://www.rfc-editor.org/rfc/rfc6716 bottom half of page 14.",
            "+        let c = toc_byte & 0b11; // Note: it's actually called \"c\" in the rfc.",
            "+        let num_frames = match c {",
            "+            0 => 1,",
            "+            1 | 2 => 2,",
            "+            3 => match packet.get(1) {",
            "+                Some(byte) => {",
            "+                    // TOC byte is followed by number of frames. See page 18 section 3.2.5 code 3",
            "+                    let m = byte & 0b11111; // Note: it's actually called \"M\" in the rfc.",
            "+                    m as u64",
            "+                }",
            "+                None => {",
            "+                    // What to do here? I'd like to return an error but this is an infalliable",
            "+                    // trait.",
            "+                    warn!(\"opus code 3 packet with no following byte containing number of frames\");",
            "+                    return 0;",
            "+                }",
            "+            },",
            "+            _ => unreachable!(\"masked 2 bits\"),",
            "+        };",
            "+        // Look up the packet length and return it.",
            "+        frame_duration * num_frames",
            "     }",
            " }",
            " ",
            " struct OpusMapper {",
            "     codec_params: CodecParameters,",
            "     need_comment: bool,",
            " }",
            "@@ -180,15 +234,15 @@",
            " ",
            "     fn make_parser(&self) -> Option<Box<dyn super::PacketParser>> {",
            "         Some(Box::new(OpusPacketParser {}))",
            "     }",
            " ",
            "     fn map_packet(&mut self, packet: &[u8]) -> Result<MapResult> {",
            "         if !self.need_comment {",
            "-            Ok(MapResult::StreamData { dur: 0 })",
            "+            Ok(MapResult::StreamData { dur: OpusPacketParser {}.parse_next_packet_dur(packet) })",
            "         }",
            "         else {",
            "             let mut reader = BufReader::new(packet);",
            " ",
            "             // Read the header signature.",
            "             let mut sig = [0; 8];",
            "             reader.read_buf_exact(&mut sig)?;"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-wav/src/chunks.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-wav/src/chunks.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-wav/src/chunks.rs",
            "@@ -11,15 +11,15 @@",
            " use symphonia_core::audio::Channels;",
            " use symphonia_core::codecs::CodecType;",
            " use symphonia_core::codecs::{",
            "     CODEC_TYPE_ADPCM_IMA_WAV, CODEC_TYPE_ADPCM_MS, CODEC_TYPE_PCM_ALAW, CODEC_TYPE_PCM_F32LE,",
            "     CODEC_TYPE_PCM_F64LE, CODEC_TYPE_PCM_MULAW, CODEC_TYPE_PCM_S16LE, CODEC_TYPE_PCM_S24LE,",
            "     CODEC_TYPE_PCM_S32LE, CODEC_TYPE_PCM_U8,",
            " };",
            "-use symphonia_core::errors::{decode_error, unsupported_error, Result};",
            "+use symphonia_core::errors::{decode_error, unsupported_error, Error, Result};",
            " use symphonia_core::io::ReadBytes;",
            " use symphonia_core::meta::Tag;",
            " use symphonia_metadata::riff;",
            " ",
            " use log::info;",
            " ",
            " use crate::PacketInfo;",
            "@@ -34,14 +34,71 @@",
            " ",
            " impl ParseChunkTag for NullChunks {",
            "     fn parse_tag(_tag: [u8; 4], _len: u32) -> Option<Self> {",
            "         None",
            "     }",
            " }",
            " ",
            "+fn fix_channel_mask(mut channel_mask: u32, n_channels: u16) -> u32 {",
            "+    let channel_diff = n_channels as i32 - channel_mask.count_ones() as i32;",
            "+",
            "+    if channel_diff != 0 {",
            "+        info!(\"Channel mask not set correctly, channel positions may be incorrect!\");",
            "+    }",
            "+",
            "+    // Check that the number of ones in the channel mask match the number of channels.",
            "+    if channel_diff > 0 {",
            "+        // Too few ones in mask so add extra ones above the most significant one",
            "+        let shift = 32 - (!channel_mask).leading_ones();",
            "+        channel_mask |= ((1 << channel_diff) - 1) << shift;",
            "+    }",
            "+    else {",
            "+        // Too many ones in mask so remove the most significant extra ones",
            "+        while channel_mask.count_ones() != n_channels as u32 {",
            "+            let highest_one = 31 - (!channel_mask).leading_ones();",
            "+            channel_mask &= !(1 << highest_one);",
            "+        }",
            "+    }",
            "+",
            "+    channel_mask",
            "+}",
            "+",
            "+#[test]",
            "+fn test_fix_channel_mask() {",
            "+    // Too few",
            "+    assert_eq!(fix_channel_mask(0, 9), 0b111111111);",
            "+    assert_eq!(fix_channel_mask(0b101000, 5), 0b111101000);",
            "+",
            "+    // Too many",
            "+    assert_eq!(fix_channel_mask(0b1111111, 0), 0);",
            "+    assert_eq!(fix_channel_mask(0b101110111010, 5), 0b10111010);",
            "+    assert_eq!(fix_channel_mask(0xFFFFFFFF, 8), 0b11111111);",
            "+}",
            "+",
            "+fn try_channel_count_to_mask(count: u16) -> Result<Channels> {",
            "+    (1..=32)",
            "+        .contains(&count)",
            "+        .then(|| Channels::from_bits(((1u64 << count) - 1) as u32))",
            "+        .flatten()",
            "+        .ok_or(Error::DecodeError(\"wav: invalid channel count\"))",
            "+}",
            "+",
            "+#[test]",
            "+fn test_try_channel_count_to_mask() {",
            "+    assert!(try_channel_count_to_mask(0).is_err());",
            "+",
            "+    for i in 1..27 {",
            "+        assert!(try_channel_count_to_mask(i).is_ok());",
            "+    }",
            "+",
            "+    for i in 27..u16::MAX {",
            "+        assert!(try_channel_count_to_mask(i).is_err());",
            "+    }",
            "+}",
            "+",
            " /// `ChunksReader` reads chunks from a `ByteStream`. It is generic across a type, usually an enum,",
            " /// implementing the `ParseChunkTag` trait. When a new chunk is encountered in the stream,",
            " /// `parse_tag` on T is called to return an object capable of parsing/reading that chunk or `None`.",
            " /// This makes reading the actual chunk data lazy in that the  chunk is not read until the object is",
            " /// consumed.",
            " pub struct ChunksReader<T: ParseChunkTag> {",
            "     len: u32,",
            "@@ -265,22 +322,15 @@",
            "             _ => {",
            "                 return decode_error(",
            "                     \"wav: bits per sample for fmt_pcm must be 8, 16, 24 or 32 bits\",",
            "                 )",
            "             }",
            "         };",
            " ",
            "-        // The PCM format only supports 1 or 2 channels, for mono and stereo channel layouts,",
            "-        // respectively.",
            "-        let channels = match n_channels {",
            "-            1 => Channels::FRONT_LEFT,",
            "-            2 => Channels::FRONT_LEFT | Channels::FRONT_RIGHT,",
            "-            _ => return decode_error(\"wav: channel layout is not stereo or mono for fmt_pcm\"),",
            "-        };",
            "-",
            "+        let channels = try_channel_count_to_mask(n_channels)?;",
            "         Ok(WaveFormatData::Pcm(WaveFormatPcm { bits_per_sample, channels, codec }))",
            "     }",
            " ",
            "     fn read_adpcm_fmt<B: ReadBytes>(",
            "         reader: &mut B,",
            "         bits_per_sample: u16,",
            "         n_channels: u16,",
            "@@ -305,61 +355,54 @@",
            "             CODEC_TYPE_ADPCM_IMA_WAV if extra_size != 2 => {",
            "                 return decode_error(\"wav: malformed fmt_adpcm chunk\");",
            "             }",
            "             _ => (),",
            "         }",
            "         reader.ignore_bytes(extra_size)?;",
            " ",
            "-        // The ADPCM format only supports 1 or 2 channels, for mono and stereo channel layouts,",
            "-        // respectively.",
            "-        let channels = match n_channels {",
            "-            1 => Channels::FRONT_LEFT,",
            "-            2 => Channels::FRONT_LEFT | Channels::FRONT_RIGHT,",
            "-            _ => return decode_error(\"wav: channel layout is not stereo or mono for fmt_adpcm\"),",
            "-        };",
            "+        let channels = try_channel_count_to_mask(n_channels)?;",
            "         Ok(WaveFormatData::Adpcm(WaveFormatAdpcm { bits_per_sample, channels, codec }))",
            "     }",
            " ",
            "     fn read_ieee_fmt<B: ReadBytes>(",
            "         reader: &mut B,",
            "         bits_per_sample: u16,",
            "         n_channels: u16,",
            "         len: u32,",
            "     ) -> Result<WaveFormatData> {",
            "         // WaveFormat for a IEEE format should not be extended, but it may still have an extra data",
            "         // length parameter.",
            "-        if len == 18 {",
            "-            let extra_size = reader.read_u16()?;",
            "-",
            "-            if extra_size != 0 {",
            "-                return decode_error(\"wav: extra data not expected for fmt_ieee chunk\");",
            "+        match len {",
            "+            16 => (),",
            "+            18 => {",
            "+                let extra_size = reader.read_u16()?;",
            "+                if extra_size != 0 {",
            "+                    return decode_error(\"wav: extra data not expected for fmt_ieee chunk\");",
            "+                }",
            "             }",
            "-        }",
            "-        else if len > 16 {",
            "-            return decode_error(\"wav: malformed fmt_ieee chunk\");",
            "+            40 => {",
            "+                // WAVEFORMATEXTENSIBLE is used for formats having more than two channels",
            "+                // or higher sample resolutions than allowed by WAVEFORMATEX but for now",
            "+                // we just ignore it",
            "+                let _ = reader.ignore_bytes(40 - 16);",
            "+            }",
            "+            _ => return decode_error(\"wav: malformed fmt_ieee chunk\"),",
            "         }",
            " ",
            "         // Officially, only 32-bit floats are supported, but Symphonia can handle 64-bit floats.",
            "         //",
            "         // Select the appropriate codec using bits per sample. Samples are always interleaved and",
            "         // little-endian encoded for the IEEE Float format.",
            "         let codec = match bits_per_sample {",
            "             32 => CODEC_TYPE_PCM_F32LE,",
            "             64 => CODEC_TYPE_PCM_F64LE,",
            "             _ => return decode_error(\"wav: bits per sample for fmt_ieee must be 32 or 64 bits\"),",
            "         };",
            " ",
            "-        // The IEEE format only supports 1 or 2 channels, for mono and stereo channel layouts,",
            "-        // respectively.",
            "-        let channels = match n_channels {",
            "-            1 => Channels::FRONT_LEFT,",
            "-            2 => Channels::FRONT_LEFT | Channels::FRONT_RIGHT,",
            "-            _ => return decode_error(\"wav: channel layout is not stereo or mono for fmt_ieee\"),",
            "-        };",
            "-",
            "+        let channels = try_channel_count_to_mask(n_channels)?;",
            "         Ok(WaveFormatData::IeeeFloat(WaveFormatIeeeFloat { channels, codec }))",
            "     }",
            " ",
            "     fn read_ext_fmt<B: ReadBytes>(",
            "         reader: &mut B,",
            "         bits_per_coded_sample: u16,",
            "         n_channels: u16,",
            "@@ -390,20 +433,15 @@",
            "         // be at most bits per coded sample long.",
            "         if bits_per_sample > bits_per_coded_sample {",
            "             return decode_error(",
            "                 \"wav: bits per sample must be <= bits per coded sample for fmt_ext\",",
            "             );",
            "         }",
            " ",
            "-        let channel_mask = reader.read_u32()?;",
            "-",
            "-        // The number of ones in the channel mask should match the number of channels.",
            "-        if channel_mask.count_ones() != u32::from(n_channels) {",
            "-            return decode_error(\"wav: channel mask mismatch with number of channels for fmt_ext\");",
            "-        }",
            "+        let channel_mask = fix_channel_mask(reader.read_u32()?, n_channels);",
            " ",
            "         // Try to map channels.",
            "         let channels = match Channels::from_bits(channel_mask) {",
            "             Some(channels) => channels,",
            "             _ => return unsupported_error(\"wav: too many channels in mask for fmt_ext\"),",
            "         };",
            " ",
            "@@ -502,20 +540,15 @@",
            " ",
            "         let extra_size = reader.read_u16()?;",
            " ",
            "         if extra_size > 0 {",
            "             reader.ignore_bytes(u64::from(extra_size))?;",
            "         }",
            " ",
            "-        let channels = match n_channels {",
            "-            1 => Channels::FRONT_LEFT,",
            "-            2 => Channels::FRONT_LEFT | Channels::FRONT_RIGHT,",
            "-            _ => return decode_error(\"wav: channel layout is not stereo or mono for fmt_alaw\"),",
            "-        };",
            "-",
            "+        let channels = try_channel_count_to_mask(n_channels)?;",
            "         Ok(WaveFormatData::ALaw(WaveFormatALaw { codec: CODEC_TYPE_PCM_ALAW, channels }))",
            "     }",
            " ",
            "     fn read_mulaw_pcm_fmt<B: ReadBytes>(",
            "         reader: &mut B,",
            "         n_channels: u16,",
            "         len: u32,",
            "@@ -526,20 +559,15 @@",
            " ",
            "         let extra_size = reader.read_u16()?;",
            " ",
            "         if extra_size > 0 {",
            "             reader.ignore_bytes(u64::from(extra_size))?;",
            "         }",
            " ",
            "-        let channels = match n_channels {",
            "-            1 => Channels::FRONT_LEFT,",
            "-            2 => Channels::FRONT_LEFT | Channels::FRONT_RIGHT,",
            "-            _ => return decode_error(\"wav: channel layout is not stereo or mono for fmt_mulaw\"),",
            "-        };",
            "-",
            "+        let channels = try_channel_count_to_mask(n_channels)?;",
            "         Ok(WaveFormatData::MuLaw(WaveFormatMuLaw { codec: CODEC_TYPE_PCM_MULAW, channels }))",
            "     }",
            " ",
            "     pub(crate) fn packet_info(&self) -> Result<PacketInfo> {",
            "         match self.format_data {",
            "             WaveFormatData::Adpcm(WaveFormatAdpcm { codec, bits_per_sample, .. })",
            "             //| WaveFormatData::Extensible(WaveFormatExtensible { codec, bits_per_sample, .. })"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-format-wav/src/lib.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-format-wav/src/lib.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-format-wav/src/lib.rs",
            "@@ -1,14 +1,15 @@",
            " // Symphonia",
            " // Copyright (c) 2019-2022 The Project Symphonia Developers.",
            " //",
            " // This Source Code Form is subject to the terms of the Mozilla Public",
            " // License, v. 2.0. If a copy of the MPL was not distributed with this",
            " // file, You can obtain one at https://mozilla.org/MPL/2.0/.",
            " ",
            "+#![deprecated(since = \"0.5.4\", note = \"superseded by `symphonia-format-riff`\")]",
            " #![warn(rust_2018_idioms)]",
            " #![forbid(unsafe_code)]",
            " // The following lints are allowed in all Symphonia crates. Please see clippy.toml for their",
            " // justification.",
            " #![allow(clippy::comparison_chain)]",
            " #![allow(clippy::excessive_precision)]",
            " #![allow(clippy::identity_op)]"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-metadata/src/lib.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-metadata/src/lib.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-metadata/src/lib.rs",
            "@@ -10,12 +10,13 @@",
            " // The following lints are allowed in all Symphonia crates. Please see clippy.toml for their",
            " // justification.",
            " #![allow(clippy::comparison_chain)]",
            " #![allow(clippy::excessive_precision)]",
            " #![allow(clippy::identity_op)]",
            " #![allow(clippy::manual_range_contains)]",
            " ",
            "+pub mod flac;",
            " pub mod id3v1;",
            " pub mod id3v2;",
            " pub mod itunes;",
            " pub mod riff;",
            " pub mod vorbis;"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-metadata/src/vorbis.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-metadata/src/vorbis.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-metadata/src/vorbis.rs",
            "@@ -1,22 +1,27 @@",
            " // Symphonia",
            "-// Copyright (c) 2019-2022 The Project Symphonia Developers.",
            "+// Copyright (c) 2019-2024 The Project Symphonia Developers.",
            " //",
            " // This Source Code Form is subject to the terms of the Mozilla Public",
            " // License, v. 2.0. If a copy of the MPL was not distributed with this",
            " // file, You can obtain one at https://mozilla.org/MPL/2.0/.",
            " ",
            " //! A Vorbic COMMENT metadata reader for FLAC or OGG formats.",
            " ",
            "-use lazy_static::lazy_static;",
            " use std::collections::HashMap;",
            "+",
            "+use lazy_static::lazy_static;",
            "+use log::warn;",
            "+",
            " use symphonia_core::errors::Result;",
            "-use symphonia_core::io::ReadBytes;",
            "+use symphonia_core::io::{BufReader, ReadBytes};",
            " use symphonia_core::meta::{MetadataBuilder, StandardTagKey, Tag, Value};",
            " ",
            "+use crate::flac;",
            "+",
            " lazy_static! {",
            "     static ref VORBIS_COMMENT_MAP: HashMap<&'static str, StandardTagKey> = {",
            "         let mut m = HashMap::new();",
            "         m.insert(\"album artist\"                , StandardTagKey::AlbumArtist);",
            "         m.insert(\"album\"                       , StandardTagKey::Album);",
            "         m.insert(\"albumartist\"                 , StandardTagKey::AlbumArtist);",
            "         m.insert(\"albumartistsort\"             , StandardTagKey::SortAlbumArtist);",
            "@@ -106,35 +111,51 @@",
            "         m.insert(\"version\"                     , StandardTagKey::Version);",
            "         m.insert(\"writer\"                      , StandardTagKey::Writer);",
            "         m.insert(\"year\"                        , StandardTagKey::Date);",
            "         m",
            "     };",
            " }",
            " ",
            "+/// Parse a string containing a base64 encoded FLAC picture block into a visual.",
            "+fn parse_base64_picture_block(encoded: &str, metadata: &mut MetadataBuilder) {",
            "+    if let Some(data) = base64_decode(encoded) {",
            "+        if flac::read_picture_block(&mut BufReader::new(&data), metadata).is_err() {",
            "+            warn!(\"invalid picture block data\");",
            "+        }",
            "+    }",
            "+    else {",
            "+        warn!(\"the base64 encoding of a picture block is invalid\");",
            "+    }",
            "+}",
            "+",
            " /// Parse the given Vorbis Comment string into a `Tag`.",
            "-fn parse(tag: &str) -> Tag {",
            "+fn parse_comment(tag: &str, metadata: &mut MetadataBuilder) {",
            "     // Vorbis Comments (aka tags) are stored as <key>=<value> where <key> is",
            "     // a reduced ASCII-only identifier and <value> is a UTF8 value.",
            "     //",
            "     // <Key> must only contain ASCII 0x20 through 0x7D, with 0x3D ('=') excluded.",
            "     // ASCII 0x41 through 0x5A inclusive (A-Z) is to be considered equivalent to",
            "     // ASCII 0x61 through 0x7A inclusive (a-z) for tag matching.",
            " ",
            "-    let field: Vec<&str> = tag.splitn(2, '=').collect();",
            "+    if let Some((key, value)) = tag.split_once('=') {",
            "+        let key_lower = key.to_lowercase();",
            " ",
            "-    // Attempt to assign a standardized tag key.",
            "-    let std_tag = VORBIS_COMMENT_MAP.get(field[0].to_lowercase().as_str()).copied();",
            "+        // A comment with a key \"METADATA_BLOCK_PICTURE\" is a FLAC picture block encoded in base64.",
            "+        // Attempt to decode it as such. If this fails in any way, treat the comment as a regular",
            "+        // tag.",
            "+        if key_lower == \"metadata_block_picture\" {",
            "+            parse_base64_picture_block(value, metadata);",
            "+        }",
            "+        else {",
            "+            // Attempt to assign a standardized tag key.",
            "+            let std_tag = VORBIS_COMMENT_MAP.get(key_lower.as_str()).copied();",
            " ",
            "-    // The value field was empty so only the key field exists. Create an empty tag for the given",
            "-    // key field.",
            "-    if field.len() == 1 {",
            "-        return Tag::new(std_tag, field[0], Value::from(\"\"));",
            "+            metadata.add_tag(Tag::new(std_tag, key, Value::from(value)));",
            "+        }",
            "     }",
            "-",
            "-    Tag::new(std_tag, field[0], Value::from(field[1]))",
            " }",
            " ",
            " pub fn read_comment_no_framing<B: ReadBytes>(",
            "     reader: &mut B,",
            "     metadata: &mut MetadataBuilder,",
            " ) -> Result<()> {",
            "     // Read the vendor string length in bytes.",
            "@@ -147,16 +168,134 @@",
            "     let n_comments = reader.read_u32()? as usize;",
            " ",
            "     for _ in 0..n_comments {",
            "         // Read the comment string length in bytes.",
            "         let comment_length = reader.read_u32()?;",
            " ",
            "         // Read the comment string.",
            "-        let mut comment_byte = vec![0; comment_length as usize];",
            "-        reader.read_buf_exact(&mut comment_byte)?;",
            "+        let mut comment_bytes = vec![0; comment_length as usize];",
            "+        reader.read_buf_exact(&mut comment_bytes)?;",
            " ",
            "         // Parse the comment string into a Tag and insert it into the parsed tag list.",
            "-        metadata.add_tag(parse(&String::from_utf8_lossy(&comment_byte)));",
            "+        parse_comment(&String::from_utf8_lossy(&comment_bytes), metadata);",
            "     }",
            " ",
            "     Ok(())",
            " }",
            "+",
            "+/// Decode a RFC4648 Base64 encoded string.",
            "+fn base64_decode(encoded: &str) -> Option<Box<[u8]>> {",
            "+    // A sentinel value indicating that an invalid symbol was encountered.",
            "+    const BAD_SYM: u8 = 0xff;",
            "+",
            "+    /// Generates a lookup table mapping RFC4648 base64 symbols to their 6-bit decoded values at",
            "+    /// compile time.",
            "+    const fn rfc4648_base64_symbols() -> [u8; 256] {",
            "+        const SYMBOLS: &[u8; 64] =",
            "+            b\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\";",
            "+",
            "+        let mut table = [BAD_SYM; 256];",
            "+        let mut i = 0;",
            "+",
            "+        while i < SYMBOLS.len() {",
            "+            table[SYMBOLS[i] as usize] = i as u8;",
            "+            i += 1",
            "+        }",
            "+",
            "+        table",
            "+    }",
            "+",
            "+    const SYM_VALUE: [u8; 256] = rfc4648_base64_symbols();",
            "+",
            "+    // Trim padding, since it's not required for decoding.",
            "+    let encoded = encoded.trim_end_matches('=');",
            "+",
            "+    // Each valid base64 symbol decodes to 6 bits. Therefore, the decoded byte length is 3 / 4 the",
            "+    // number of symbols in the base64 encoded string.",
            "+    let mut decoded = Vec::with_capacity((encoded.len() * 3) / 4);",
            "+",
            "+    // Decode in chunks of 4 symbols, yielding 3 bytes per chunk. Since base64 symbols are ASCII",
            "+    // characters (1 byte per character), iterate over the bytes of the base64 string instead of",
            "+    // chars (4 bytes per character). This allows the use of a lookup table to determine the symbol",
            "+    // value.",
            "+    let mut iter = encoded.as_bytes().chunks_exact(4);",
            "+",
            "+    for enc in &mut iter {",
            "+        let v0 = SYM_VALUE[usize::from(enc[0])];",
            "+        let v1 = SYM_VALUE[usize::from(enc[1])];",
            "+        let v2 = SYM_VALUE[usize::from(enc[2])];",
            "+        let v3 = SYM_VALUE[usize::from(enc[3])];",
            "+",
            "+        // Check for invalid symbols.",
            "+        if v0 == BAD_SYM || v1 == BAD_SYM || v2 == BAD_SYM || v3 == BAD_SYM {",
            "+            return None;",
            "+        }",
            "+",
            "+        // 6 bits from v0, 2 bits from v1 (4 remaining).",
            "+        decoded.push(((v0 & 0x3f) << 2) | (v1 >> 4));",
            "+        // 4 bits from v1, 4 bits from v2 (2 remaining).",
            "+        decoded.push(((v1 & 0x0f) << 4) | (v2 >> 2));",
            "+        // 2 bits from v2, 6 bits from v3 (0 remaining).",
            "+        decoded.push(((v2 & 0x03) << 6) | (v3 >> 0));",
            "+    }",
            "+",
            "+    // Decode the remaining 2 to 3 symbols.",
            "+    let rem = iter.remainder();",
            "+",
            "+    // If there are atleast 2 symbols remaining, then a minimum of one extra byte may be decoded.",
            "+    if rem.len() >= 2 {",
            "+        let v0 = SYM_VALUE[usize::from(rem[0])];",
            "+        let v1 = SYM_VALUE[usize::from(rem[1])];",
            "+",
            "+        if v0 == BAD_SYM || v1 == BAD_SYM {",
            "+            return None;",
            "+        }",
            "+",
            "+        decoded.push(((v0 & 0x3f) << 2) | (v1 >> 4));",
            "+",
            "+        // If there were 3 symbols remaining, then one additional byte may be decoded.",
            "+        if rem.len() >= 3 {",
            "+            let v2 = SYM_VALUE[usize::from(rem[2])];",
            "+",
            "+            if v2 == BAD_SYM {",
            "+                return None;",
            "+            }",
            "+",
            "+            decoded.push(((v1 & 0x0f) << 4) | (v2 >> 2));",
            "+        }",
            "+    }",
            "+    else if rem.len() == 1 {",
            "+        // Atleast 2 symbols are required to decode a single byte. Therefore, this is an error.",
            "+        return None;",
            "+    }",
            "+",
            "+    Some(decoded.into_boxed_slice())",
            "+}",
            "+",
            "+#[cfg(test)]",
            "+mod tests {",
            "+    use super::base64_decode;",
            "+",
            "+    #[test]",
            "+    fn verify_base64_decode() {",
            "+        // Valid, with padding.",
            "+        assert_eq!(Some(b\"\".as_slice()), base64_decode(\"\").as_deref());",
            "+        assert_eq!(Some(b\"f\".as_slice()), base64_decode(\"Zg==\").as_deref());",
            "+        assert_eq!(Some(b\"fo\".as_slice()), base64_decode(\"Zm8=\").as_deref());",
            "+        assert_eq!(Some(b\"foo\".as_slice()), base64_decode(\"Zm9v\").as_deref());",
            "+        assert_eq!(Some(b\"foob\".as_slice()), base64_decode(\"Zm9vYg==\").as_deref());",
            "+        assert_eq!(Some(b\"fooba\".as_slice()), base64_decode(\"Zm9vYmE=\").as_deref());",
            "+        assert_eq!(Some(b\"foobar\".as_slice()), base64_decode(\"Zm9vYmFy\").as_deref());",
            "+        // Valid, without padding.",
            "+        assert_eq!(Some(b\"\".as_slice()), base64_decode(\"\").as_deref());",
            "+        assert_eq!(Some(b\"f\".as_slice()), base64_decode(\"Zg\").as_deref());",
            "+        assert_eq!(Some(b\"fo\".as_slice()), base64_decode(\"Zm8\").as_deref());",
            "+        assert_eq!(Some(b\"foo\".as_slice()), base64_decode(\"Zm9v\").as_deref());",
            "+        assert_eq!(Some(b\"foob\".as_slice()), base64_decode(\"Zm9vYg\").as_deref());",
            "+        assert_eq!(Some(b\"fooba\".as_slice()), base64_decode(\"Zm9vYmE\").as_deref());",
            "+        assert_eq!(Some(b\"foobar\".as_slice()), base64_decode(\"Zm9vYmFy\").as_deref());",
            "+        // Invalid.",
            "+        assert_eq!(None, base64_decode(\"a\").as_deref());",
            "+        assert_eq!(None, base64_decode(\"ab!c\").as_deref());",
            "+        assert_eq!(None, base64_decode(\"ab=c\").as_deref());",
            "+    }",
            "+}"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-play/src/main.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-play/src/main.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-play/src/main.rs",
            "@@ -8,14 +8,15 @@",
            " #![warn(rust_2018_idioms)]",
            " #![forbid(unsafe_code)]",
            " // Justification: Fields on DecoderOptions and FormatOptions may change at any time, but",
            " // symphonia-play doesn't want to be updated every time those fields change, therefore always fill",
            " // in the remaining fields with default values.",
            " #![allow(clippy::needless_update)]",
            " ",
            "+use std::ffi::{OsStr, OsString};",
            " use std::fs::File;",
            " use std::io::Write;",
            " use std::path::Path;",
            " ",
            " use lazy_static::lazy_static;",
            " use symphonia::core::codecs::{DecoderOptions, FinalizeResult, CODEC_TYPE_NULL};",
            " use symphonia::core::errors::{Error, Result};",
            "@@ -29,28 +30,53 @@",
            " use log::{error, info, warn};",
            " ",
            " mod output;",
            " ",
            " #[cfg(not(target_os = \"linux\"))]",
            " mod resampler;",
            " ",
            "+enum SeekPosition {",
            "+    Time(f64),",
            "+    Timetamp(u64),",
            "+}",
            "+",
            " fn main() {",
            "     pretty_env_logger::init();",
            " ",
            "     let args = clap::Command::new(\"Symphonia Play\")",
            "         .version(\"1.0\")",
            "         .author(\"Philip Deljanov <philip.deljanov@gmail.com>\")",
            "         .about(\"Play audio with Symphonia\")",
            "         .arg(",
            "             Arg::new(\"seek\")",
            "                 .long(\"seek\")",
            "                 .short('s')",
            "                 .value_name(\"TIME\")",
            "-                .help(\"Seek to the given time in seconds\")",
            "-                .conflicts_with_all(&[\"verify\", \"decode-only\", \"verify-only\", \"probe-only\"]),",
            "+                .help(\"Seek to the time in seconds\")",
            "+                .conflicts_with_all(&[",
            "+                    \"seek-ts\",",
            "+                    \"decode-only\",",
            "+                    \"probe-only\",",
            "+                    \"verify\",",
            "+                    \"verify-only\",",
            "+                ]),",
            "+        )",
            "+        .arg(",
            "+            Arg::new(\"seek-ts\")",
            "+                .long(\"seek-ts\")",
            "+                .short('S')",
            "+                .value_name(\"TIMESTAMP\")",
            "+                .help(\"Seek to the timestamp in timebase units\")",
            "+                .conflicts_with_all(&[",
            "+                    \"seek\",",
            "+                    \"decode-only\",",
            "+                    \"probe-only\",",
            "+                    \"verify\",",
            "+                    \"verify-only\",",
            "+                ]),",
            "         )",
            "         .arg(",
            "             Arg::new(\"track\").long(\"track\").short('t').value_name(\"TRACK\").help(\"The track to use\"),",
            "         )",
            "         .arg(",
            "             Arg::new(\"decode-only\")",
            "                 .long(\"decode-only\")",
            "@@ -76,14 +102,19 @@",
            "                 .help(\"Verify the decoded audio is valid during playback\"),",
            "         )",
            "         .arg(Arg::new(\"no-progress\").long(\"no-progress\").help(\"Do not display playback progress\"))",
            "         .arg(",
            "             Arg::new(\"no-gapless\").long(\"no-gapless\").help(\"Disable gapless decoding and playback\"),",
            "         )",
            "         .arg(",
            "+            Arg::new(\"dump-visuals\")",
            "+                .long(\"dump-visuals\")",
            "+                .help(\"Dump all visuals to the current working directory\"),",
            "+        )",
            "+        .arg(",
            "             Arg::new(\"INPUT\")",
            "                 .help(\"The input file path, or - to use standard input\")",
            "                 .required(true)",
            "                 .index(1),",
            "         )",
            "         .get_matches();",
            " ",
            "@@ -96,26 +127,25 @@",
            "         }",
            "     };",
            " ",
            "     std::process::exit(code)",
            " }",
            " ",
            " fn run(args: &ArgMatches) -> Result<i32> {",
            "-    let path_str = args.value_of(\"INPUT\").unwrap();",
            "+    let path = Path::new(args.value_of(\"INPUT\").unwrap());",
            " ",
            "     // Create a hint to help the format registry guess what format reader is appropriate.",
            "     let mut hint = Hint::new();",
            " ",
            "     // If the path string is '-' then read from standard input.",
            "-    let source = if path_str == \"-\" {",
            "+    let source = if path.as_os_str() == \"-\" {",
            "         Box::new(ReadOnlySource::new(std::io::stdin())) as Box<dyn MediaSource>",
            "     }",
            "     else {",
            "         // Othwerise, get a Path from the path string.",
            "-        let path = Path::new(path_str);",
            " ",
            "         // Provide the file extension as a hint.",
            "         if let Some(extension) = path.extension() {",
            "             if let Some(extension_str) = extension.to_str() {",
            "                 hint.with_extension(extension_str);",
            "             }",
            "         }",
            "@@ -140,40 +170,57 @@",
            "     };",
            " ",
            "     let no_progress = args.is_present(\"no-progress\");",
            " ",
            "     // Probe the media source stream for metadata and get the format reader.",
            "     match symphonia::default::get_probe().format(&hint, mss, &format_opts, &metadata_opts) {",
            "         Ok(mut probed) => {",
            "+            // Dump visuals if requested.",
            "+            if args.is_present(\"dump-visuals\") {",
            "+                let name = match path.file_name() {",
            "+                    Some(name) if name != \"-\" => name,",
            "+                    _ => OsStr::new(\"NoName\"),",
            "+                };",
            "+",
            "+                dump_visuals(&mut probed, name);",
            "+            }",
            "+",
            "+            // Select the operating mode.",
            "             if args.is_present(\"verify-only\") {",
            "                 // Verify-only mode decodes and verifies the audio, but does not play it.",
            "                 decode_only(probed.format, &DecoderOptions { verify: true, ..Default::default() })",
            "             }",
            "             else if args.is_present(\"decode-only\") {",
            "                 // Decode-only mode decodes the audio, but does not play or verify it.",
            "                 decode_only(probed.format, &DecoderOptions { verify: false, ..Default::default() })",
            "             }",
            "             else if args.is_present(\"probe-only\") {",
            "                 // Probe-only mode only prints information about the format, tracks, metadata, etc.",
            "-                print_format(path_str, &mut probed);",
            "+                print_format(path, &mut probed);",
            "                 Ok(0)",
            "             }",
            "             else {",
            "                 // Playback mode.",
            "-                print_format(path_str, &mut probed);",
            "+                print_format(path, &mut probed);",
            " ",
            "                 // If present, parse the seek argument.",
            "-                let seek_time = args.value_of(\"seek\").map(|p| p.parse::<f64>().unwrap_or(0.0));",
            "+                let seek = if let Some(time) = args.value_of(\"seek\") {",
            "+                    Some(SeekPosition::Time(time.parse::<f64>().unwrap_or(0.0)))",
            "+                }",
            "+                else {",
            "+                    args.value_of(\"seek-ts\")",
            "+                        .map(|ts| SeekPosition::Timetamp(ts.parse::<u64>().unwrap_or(0)))",
            "+                };",
            " ",
            "                 // Set the decoder options.",
            "                 let decode_opts =",
            "                     DecoderOptions { verify: args.is_present(\"verify\"), ..Default::default() };",
            " ",
            "                 // Play it!",
            "-                play(probed.format, track, seek_time, &decode_opts, no_progress)",
            "+                play(probed.format, track, seek, &decode_opts, no_progress)",
            "             }",
            "         }",
            "         Err(err) => {",
            "             // The input was not supported by any format reader.",
            "             info!(\"the input is not supported\");",
            "             Err(err)",
            "         }",
            "@@ -221,37 +268,40 @@",
            "     track_id: u32,",
            "     seek_ts: u64,",
            " }",
            " ",
            " fn play(",
            "     mut reader: Box<dyn FormatReader>,",
            "     track_num: Option<usize>,",
            "-    seek_time: Option<f64>,",
            "+    seek: Option<SeekPosition>,",
            "     decode_opts: &DecoderOptions,",
            "     no_progress: bool,",
            " ) -> Result<i32> {",
            "     // If the user provided a track number, select that track if it exists, otherwise, select the",
            "     // first track with a known codec.",
            "     let track = track_num",
            "         .and_then(|t| reader.tracks().get(t))",
            "         .or_else(|| first_supported_track(reader.tracks()));",
            " ",
            "     let mut track_id = match track {",
            "         Some(track) => track.id,",
            "         _ => return Ok(0),",
            "     };",
            " ",
            "-    // If there is a seek time, seek the reader to the time specified and get the timestamp of the",
            "+    // If seeking, seek the reader to the time or timestamp specified and get the timestamp of the",
            "     // seeked position. All packets with a timestamp < the seeked position will not be played.",
            "     //",
            "     // Note: This is a half-baked approach to seeking! After seeking the reader, packets should be",
            "     // decoded and *samples* discarded up-to the exact *sample* indicated by required_ts. The",
            "     // current approach will discard excess samples if seeking to a sample within a packet.",
            "-    let seek_ts = if let Some(time) = seek_time {",
            "-        let seek_to = SeekTo::Time { time: Time::from(time), track_id: Some(track_id) };",
            "+    let seek_ts = if let Some(seek) = seek {",
            "+        let seek_to = match seek {",
            "+            SeekPosition::Time(t) => SeekTo::Time { time: Time::from(t), track_id: Some(track_id) },",
            "+            SeekPosition::Timetamp(ts) => SeekTo::TimeStamp { ts, track_id },",
            "+        };",
            " ",
            "         // Attempt the seek. If the seek fails, ignore the error and return a seek timestamp of 0 so",
            "         // that no samples are trimmed.",
            "         match reader.seek(SeekMode::Accurate, seek_to) {",
            "             Ok(seeked_to) => seeked_to.required_ts,",
            "             Err(Error::ResetRequired) => {",
            "                 print_tracks(reader.tracks());",
            "@@ -423,16 +473,53 @@",
            "             Ok(i32::from(!is_ok))",
            "         }",
            "         // Verification not enabled by user, or unsupported by the codec.",
            "         _ => Ok(0),",
            "     }",
            " }",
            " ",
            "-fn print_format(path: &str, probed: &mut ProbeResult) {",
            "-    println!(\"+ {}\", path);",
            "+fn dump_visual(visual: &Visual, file_name: &OsStr, index: usize) {",
            "+    let extension = match visual.media_type.to_lowercase().as_str() {",
            "+        \"image/bmp\" => \".bmp\",",
            "+        \"image/gif\" => \".gif\",",
            "+        \"image/jpeg\" => \".jpg\",",
            "+        \"image/png\" => \".png\",",
            "+        _ => \"\",",
            "+    };",
            "+",
            "+    let mut out_file_name = OsString::from(file_name);",
            "+    out_file_name.push(format!(\"-{:0>2}{}\", index, extension));",
            "+",
            "+    if let Err(err) = File::create(out_file_name).and_then(|mut file| file.write_all(&visual.data))",
            "+    {",
            "+        warn!(\"failed to dump visual due to error {}\", err);",
            "+    }",
            "+}",
            "+",
            "+fn dump_visuals(probed: &mut ProbeResult, file_name: &OsStr) {",
            "+    if let Some(metadata) = probed.format.metadata().current() {",
            "+        for (i, visual) in metadata.visuals().iter().enumerate() {",
            "+            dump_visual(visual, file_name, i);",
            "+        }",
            "+",
            "+        // Warn that certain visuals are preferred.",
            "+        if probed.metadata.get().as_ref().is_some() {",
            "+            info!(\"visuals that are part of the container format are preferentially dumped.\");",
            "+            info!(\"not dumping additional visuals that were found while probing.\");",
            "+        }",
            "+    }",
            "+    else if let Some(metadata) = probed.metadata.get().as_ref().and_then(|m| m.current()) {",
            "+        for (i, visual) in metadata.visuals().iter().enumerate() {",
            "+            dump_visual(visual, file_name, i);",
            "+        }",
            "+    }",
            "+}",
            "+",
            "+fn print_format(path: &Path, probed: &mut ProbeResult) {",
            "+    println!(\"+ {}\", path.display());",
            "     print_tracks(probed.format.tracks());",
            " ",
            "     // Prefer metadata that's provided in the container format, over other tags found during the",
            "     // probe operation.",
            "     if let Some(metadata_rev) = probed.format.metadata().current() {",
            "         print_tags(metadata_rev.tags());",
            "         print_visuals(metadata_rev.visuals());"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-play/src/output.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-play/src/output.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-play/src/output.rs",
            "@@ -76,15 +76,15 @@",
            "             // Create a PulseAudio connection.",
            "             let pa_result = psimple::Simple::new(",
            "                 None,                               // Use default server",
            "                 \"Symphonia Player\",                 // Application name",
            "                 pulse::stream::Direction::Playback, // Playback stream",
            "                 None,                               // Default playback device",
            "                 \"Music\",                            // Description of the stream",
            "-                &pa_spec,                           // Signal specificaiton",
            "+                &pa_spec,                           // Signal specification",
            "                 pa_ch_map.as_ref(),                 // Channel map",
            "                 None,                               // Custom buffering attributes",
            "             );",
            " ",
            "             match pa_result {",
            "                 Ok(pa) => Ok(Box::new(PulseAudioOutput { pa, sample_buf })),",
            "                 Err(err) => {"
          ]
        },
        {
          "file": "/home/Symphonia-0.5.4/symphonia-utils-xiph/src/flac/metadata.rs",
          "change": [
            "--- /home/Symphonia-0.5.2/symphonia-utils-xiph/src/flac/metadata.rs",
            "+++ /home/Symphonia-0.5.4/symphonia-utils-xiph/src/flac/metadata.rs",
            "@@ -2,25 +2,20 @@",
            " // Copyright (c) 2019-2022 The Project Symphonia Developers.",
            " //",
            " // This Source Code Form is subject to the terms of the Mozilla Public",
            " // License, v. 2.0. If a copy of the MPL was not distributed with this",
            " // file, You can obtain one at https://mozilla.org/MPL/2.0/.",
            " ",
            " use std::ascii;",
            "-use std::num::NonZeroU32;",
            " ",
            " use symphonia_core::audio::Channels;",
            " use symphonia_core::errors::{decode_error, Result};",
            "-use symphonia_core::formats::util::SeekIndex;",
            "-use symphonia_core::formats::{Cue, CuePoint};",
            "+use symphonia_core::formats::{util::SeekIndex, Cue, CuePoint};",
            " use symphonia_core::io::*;",
            "-use symphonia_core::meta::{ColorMode, MetadataBuilder, Size, StandardTagKey, Tag, Value};",
            "-use symphonia_core::meta::{VendorData, Visual};",
            "-",
            "-use symphonia_metadata::{id3v2, vorbis};",
            "+use symphonia_core::meta::{StandardTagKey, Tag, Value, VendorData};",
            " ",
            " #[derive(PartialEq, Eq)]",
            " pub enum MetadataBlockType {",
            "     StreamInfo,",
            "     Padding,",
            "     Application,",
            "     SeekTable,",
            "@@ -99,15 +94,15 @@",
            "     /// The total number of samples in the stream, if available.",
            "     pub n_samples: Option<u64>,",
            "     /// The MD5 hash value of the decoded audio.",
            "     pub md5: Option<[u8; 16]>,",
            " }",
            " ",
            " impl StreamInfo {",
            "-    /// Try to read a stream information block.",
            "+    /// Read a stream information block.",
            "     pub fn read<B: ReadBytes>(reader: &mut B) -> Result<StreamInfo> {",
            "         let mut info = StreamInfo {",
            "             block_len_min: 0,",
            "             block_len_max: 0,",
            "             frame_byte_len_min: 0,",
            "             frame_byte_len_max: 0,",
            "             sample_rate: 0,",
            "@@ -196,23 +191,15 @@",
            "     pub fn is_valid_size(size: u64) -> bool {",
            "         const STREAM_INFO_BLOCK_SIZE: u64 = 34;",
            " ",
            "         size == STREAM_INFO_BLOCK_SIZE",
            "     }",
            " }",
            " ",
            "-/// Try to read a comment block.",
            "-pub fn read_comment_block<B: ReadBytes>(",
            "-    reader: &mut B,",
            "-    metadata: &mut MetadataBuilder,",
            "-) -> Result<()> {",
            "-    vorbis::read_comment_no_framing(reader, metadata)",
            "-}",
            "-",
            "-/// Try to read a seek table block.",
            "+/// Read a seek table block.",
            " pub fn read_seek_table_block<B: ReadBytes>(",
            "     reader: &mut B,",
            "     block_length: u32,",
            "     table: &mut SeekIndex,",
            " ) -> Result<()> {",
            "     // The number of seek table entries is always the block length divided by the length of a single",
            "     // entry, 18 bytes.",
            "@@ -247,15 +234,15 @@",
            "             _ => return None,",
            "         }",
            "     }",
            " ",
            "     Some(result)",
            " }",
            " ",
            "-/// Try to read a cuesheet block.",
            "+/// Read a cuesheet block.",
            " pub fn read_cuesheet_block<B: ReadBytes>(reader: &mut B, cues: &mut Vec<Cue>) -> Result<()> {",
            "     // Read cuesheet catalog number. The catalog number only allows printable ASCII characters.",
            "     let mut catalog_number_buf = vec![0u8; 128];",
            "     reader.read_buf_exact(&mut catalog_number_buf)?;",
            " ",
            "     let _catalog_number = match printable_ascii_to_string(&catalog_number_buf) {",
            "         Some(s) => s,",
            "@@ -398,15 +385,15 @@",
            " ",
            "     // TODO: Should be 0 or 1 for the first index for CD-DA.",
            "     let _idx_point = ((idx_point_enc & 0xff00_0000) >> 24) as u8;",
            " ",
            "     Ok(CuePoint { start_offset_ts: n_offset_samples, tags: Vec::new() })",
            " }",
            " ",
            "-/// Try to read a vendor-specific application block.",
            "+/// Read a vendor-specific application block.",
            " pub fn read_application_block<B: ReadBytes>(",
            "     reader: &mut B,",
            "     block_length: u32,",
            " ) -> Result<VendorData> {",
            "     // Read the application identifier. Usually this is just 4 ASCII characters, but it is not",
            "     // limited to that. Non-printable ASCII characters must be escaped to create a valid UTF8",
            "     // string.",
            "@@ -416,81 +403,16 @@",
            "     )",
            "     .unwrap();",
            " ",
            "     let data = reader.read_boxed_slice_exact(block_length as usize - 4)?;",
            "     Ok(VendorData { ident, data })",
            " }",
            " ",
            "-/// Try to read a picture block.",
            "-pub fn read_picture_block<B: ReadBytes>(",
            "-    reader: &mut B,",
            "-    metadata: &mut MetadataBuilder,",
            "-) -> Result<()> {",
            "-    let type_enc = reader.read_be_u32()?;",
            "-",
            "-    // Read the Media Type length in bytes.",
            "-    let media_type_len = reader.read_be_u32()? as usize;",
            "-",
            "-    // Read the Media Type bytes",
            "-    let mut media_type_buf = vec![0u8; media_type_len];",
            "-    reader.read_buf_exact(&mut media_type_buf)?;",
            "-",
            "-    // Convert Media Type bytes to an ASCII string. Non-printable ASCII characters are invalid.",
            "-    let media_type = match printable_ascii_to_string(&media_type_buf) {",
            "-        Some(s) => s,",
            "-        None => return decode_error(\"flac: picture mime-type contains invalid characters\"),",
            "-    };",
            "-",
            "-    // Read the description length in bytes.",
            "-    let desc_len = reader.read_be_u32()? as usize;",
            "-",
            "-    // Read the description bytes.",
            "-    let mut desc_buf = vec![0u8; desc_len];",
            "-    reader.read_buf_exact(&mut desc_buf)?;",
            "-",
            "-    let desc = String::from_utf8_lossy(&desc_buf);",
            "-",
            "-    // Convert description bytes into a standard Vorbis DESCRIPTION tag.",
            "-    let tags = vec![Tag::new(Some(StandardTagKey::Description), \"DESCRIPTION\", Value::from(desc))];",
            "-",
            "-    // Read the width, and height of the visual.",
            "-    let width = reader.read_be_u32()?;",
            "-    let height = reader.read_be_u32()?;",
            "-",
            "-    // If either the width or height is 0, then the size is invalid.",
            "-    let dimensions = if width > 0 && height > 0 { Some(Size { width, height }) } else { None };",
            "-",
            "-    // Read bits-per-pixel of the visual.",
            "-    let bits_per_pixel = NonZeroU32::new(reader.read_be_u32()?);",
            "-",
            "-    // Indexed colours is only valid for image formats that use an indexed colour palette. If it is",
            "-    // 0, the image does not used indexed colours.",
            "-    let indexed_colours_enc = reader.read_be_u32()?;",
            "-",
            "-    let color_mode = match indexed_colours_enc {",
            "-        0 => Some(ColorMode::Discrete),",
            "-        _ => Some(ColorMode::Indexed(NonZeroU32::new(indexed_colours_enc).unwrap())),",
            "-    };",
            "-",
            "-    // Read the image data",
            "-    let data_len = reader.read_be_u32()? as usize;",
            "-    let data = reader.read_boxed_slice_exact(data_len)?;",
            "-",
            "-    metadata.add_visual(Visual {",
            "-        media_type,",
            "-        dimensions,",
            "-        bits_per_pixel,",
            "-        color_mode,",
            "-        usage: id3v2::util::apic_picture_type_to_visual_key(type_enc),",
            "-        tags,",
            "-        data,",
            "-    });",
            "-",
            "-    Ok(())",
            "-}",
            "+pub use symphonia_metadata::flac::read_comment_block;",
            "+pub use symphonia_metadata::flac::read_picture_block;",
            " ",
            " pub struct MetadataBlockHeader {",
            "     pub is_last: bool,",
            "     pub block_type: MetadataBlockType,",
            "     pub block_len: u32,",
            " }"
          ]
        }
      ]
    }
  }
}